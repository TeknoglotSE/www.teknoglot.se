{"meta":{"title":"stegenfeldt","subtitle":"Static. Nothing but static.","description":"Currently, this is nothing more than a playground for a dynamically generated static website.","author":"Samuel Tegenfeldt","url":"http://stegenfeldt.github.io"},"pages":[{"title":"","date":"2016-05-19T09:11:09.332Z","updated":"2016-05-19T09:11:09.332Z","comments":true,"path":"class/index.html","permalink":"http://stegenfeldt.github.io/class/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"","date":"2016-05-19T09:11:09.332Z","updated":"2016-05-19T09:11:09.332Z","comments":true,"path":"def/index.html","permalink":"http://stegenfeldt.github.io/def/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"","date":"2016-05-19T09:11:09.332Z","updated":"2016-05-19T09:11:09.332Z","comments":true,"path":"scom2007/index.html","permalink":"http://stegenfeldt.github.io/scom2007/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"","date":"2016-05-19T09:12:33.222Z","updated":"2016-05-19T09:11:09.333Z","comments":true,"path":"service-model/index.html","permalink":"http://stegenfeldt.github.io/service-model/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"","date":"2016-05-19T09:11:09.333Z","updated":"2016-05-19T09:11:09.333Z","comments":true,"path":"singleton/index.html","permalink":"http://stegenfeldt.github.io/singleton/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"About","date":"2016-05-17T22:20:57.000Z","updated":"2016-05-17T22:26:44.711Z","comments":true,"path":"About/index.html","permalink":"http://stegenfeldt.github.io/About/index.html","excerpt":"","keywords":null,"text":"Who’s stegenfeldt?A System Management consultant at Atea Sverige AB, Swedish, focusing mainly on System Center Operations Manager, System Center Service Manager some Microsoft SQL Server and OP5.Besides doing consulting I am also an MCT and are holding both the official System Center Operations Manager courses at Cornerstone and Global Knowledge and holds customized classes at customer sites. The content of this site consists of my own personal opinions (and occasionally the opinions of others) and does not officially represent my employer’s view in anyway. Included content is especially not intended to convey the views of Atea Sverige AB. Please visit www.atea.com for official information. In addition, the thoughts and opinions of participants often change, and as a weblog, this is intended to provide a semi-permanent point in time snapshot. You should not consider out of date posts to reflect participants current thoughts and opinions.","raw":null,"content":null}],"posts":[{"title":"Event Id 4001 – “Cannot Add Type” in [#SQL] MP 6.6.4.0 for [#OpsMgr2012]","slug":"Event-Id-4001-–-“Cannot-Add-Type”-in-SQL-MP-6-6-4-0-for-OpsMgr2012","date":"2016-05-19T10:22:28.000Z","updated":"2016-05-19T10:24:14.439Z","comments":true,"path":"ms/Opsmgr-2012/Event-Id-4001-–-“Cannot-Add-Type”-in-SQL-MP-6-6-4-0-for-OpsMgr2012/","link":"","permalink":"http://stegenfeldt.github.io/ms/Opsmgr-2012/Event-Id-4001-–-“Cannot-Add-Type”-in-SQL-MP-6-6-4-0-for-OpsMgr2012/","excerpt":"","keywords":null,"text":"Was troubleshooting this little error message for a customer after deploying the SQL Server Management Pack version 6.6.4.0. The event is the generic “Health Service Script” with id 4001. ´´´Management Group: REDACTED. Script: Main Module: CPUUsagePercentDataSource.ps1 :Computer Name = &#039;REDACTED.redacted.com&#039; WMI = &#039;ComputerManagement11&#039; Service Name = &#039;MSSQLSERVER&#039; SQL Instance Name = &#039;MSSQLSERVER&#039;Error occured during CPU Usage for SQL Instances data source executing.Computer: REDACTEDReason: Cannot add type. Compilation errors occurred.Position:256Offset:21 Detailed error output: Cannot add type. Compilation errors occurred.(0) : No source files specified (1) : using System; (0) : Source file &#039;C:\\Windows\\TEMP\\njdqtgfb.0.cs&#039; could not be found (1) : using System;´´´ There are some known errors to the 6.6.4.0 version of the SQL management packs, and one of them does mention “Cannot add type. Compilation errors occured.”In a thread on the Technet Forums it was suggested that it has to do with rights, but focusing mainly on the SQL instance. What caught our eyes, however, was the fact that the script is using the C:\\Windows\\TEMP folder instead of its private one. And this seems to be because it is using a few .Net components that do some sort of JIT compilation.We took a quick look using procmon, filtered on C:\\Windows\\TEMP\\ and yes indeed. The monitoring account used is trying to create and delete its temporary files in that very folder. A wild work-around appears! The work-around is simple, but cumbersome. Just make sure that the assigned RunAs account have read/write/delete rights on C:\\Windows\\TEMP.Now you just have to manage this on all your SQL-servers! yaaaay","raw":null,"content":null,"categories":[{"name":"Microsoft","slug":"ms","permalink":"http://stegenfeldt.github.io/topics/ms/"},{"name":"Opsmgr 2012","slug":"ms/Opsmgr-2012","permalink":"http://stegenfeldt.github.io/topics/ms/Opsmgr-2012/"}],"tags":[]},{"title":"OpsMgr 2012 R2 UR4 - Field Notes [#opsmgr]","slug":"opsmgr-2012-r2-ur4-field-notes","date":"2014-10-30T10:41:47.000Z","updated":"2016-05-19T09:11:09.363Z","comments":true,"path":"opsmgr2012/opsmgr-2012-r2-ur4-field-notes/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/opsmgr-2012-r2-ur4-field-notes/","excerpt":"","keywords":null,"text":"Quick and unrefined notes on Update Roll-up 4 for System Center 2012 R2 -Operations Manager PreparationThe usual routine applies. Check the KB for instructions and take not ofknown issues. Check if Kevin Holman has written something about it. As thisis an update roll up, I pre-emptively expect that gotchas in UR3 mayapply. Remember to open the update catalog in IE as the downloader is notworking in other browsers. Download, unpack, toss what languages that does not apply to your organization. It is advised to disable any mail-generating alert subscriptions during theupgrade process to avoid unnecessary spammage. Issues - So Far[updated: 2014-11-03] Got a few problems with cross-platform monitoring templates not working after the update. This was due to missing files in the update package. Make sure you download the updated version! Have not updated a customer using gateways yet, so unless theyhave fixed the issues in UR3, expect an update to this section soon. PlanningAs with all update roll-ups, you’ve got a number of MSP files to install onthe different server roles, some SQL-scripts for the OpsDB and OpsDW and a fewupdated management packs. I’ve updated the components in the following order. Management Servers (and consoles installed on them) SQL-Scripts Management Packs (might need an updated console for this) Consoles Gateway Servers Web Console Agents As usual, the first management server update takes the longest as that’swhen the process is updating the databases. You absolutely must wait for it tocomplete before updating anything else. Feel free to prepare the othermanagement servers by copying installations files, logging in and starting upyour command prompts as admin. I never update more than one management server atthe time anyway. Less to worry about that way. InstallationManagement ServersOpen a command prompt (powershell will work just fine) as Administrator andexecute the MSP-file. First management server will take some time, so bepatient. If a management server has multiple roles, you can update those whilelogged in as well. SQL-ScriptsThe installation package will unpack these scripts under %SystemDrive%\\Program Files\\System Center 2012 R2\\Operations Manager\\Server\\SQL Script for Update Rollups. Run the UR_Datawarehouse.sql one on the OpsDW first, then theUpdate_rollup_mom_db.sql on OpsDB. If you’re getting deadlocks, try again. Ifthat don’t help, stop the management server services and try again. Do notcontinue with the next script ​until you’ve succeeded with the first. If you’ve installed UR3, the OpsDW-script is pretty quick (not sure ifit’s changed at all) and the OpsDB is a bit less prone to deadlocks. Management PacksJust import the management packs from the %SystemDrive%&#92;Program Files&#92;SystemCenter 2012 R2&#92;Operations Manager&#92;Server&#92;Management Packs for Update Rollupsfolder. Might have to retry as the console can do a little poor job ofcalculating the dependencies. ConsoleThe easiest one, just install the MSP-file. GatewayInstallation is a breeze. Make sure to check %SystemDrive%\\Program Files\\System Center Operations Manager\\Gateway\\AgentManagement\\&amp;lt;architecture&amp;gt; for updatedagent files. If not, copy from same folder on any management server. Web ConsoleInstallation is very simple. Install the MSP from an administrative commandprompt. If you’re affected by KB911722 and need the web console fixes, youneed to edit %windir%\\Microsoft.NET\\Framework64\\v2.0.50727\\CONFIG\\web.configby adding the following line: &amp;lt;machineKey validationKey=&quot;AutoGenerate,IsolateApps&quot; decryptionKey=&quot;AutoGenerate,IsolateApps&quot; validation=&quot;3DES&quot; decryption=&quot;3DES&quot;/&amp;gt; AgentsNormal update procedure applies. Use “Pending Management”, SCCM, manualinstallations or whatever method you’d like. SummaryIf you already have UR3, this one is very quick. If you are updating a freshinstallation, wait a day or your management group may end up uninitialized forreasons. Remember to enable your subscriptions when done.&nbsp; GLHF!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Field Notes","slug":"Field-Notes","permalink":"http://stegenfeldt.github.io/tag/Field-Notes/"},{"name":"Update Rollup","slug":"Update-Rollup","permalink":"http://stegenfeldt.github.io/tag/Update-Rollup/"}]},{"title":"SquaredUp Installation - Manual? Pfffft! [#opsmgr #squaredup]","slug":"squaredup-installation","date":"2014-09-09T14:38:36.000Z","updated":"2016-05-19T09:11:09.365Z","comments":true,"path":"opsmgr2012/squaredup-installation/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/squaredup-installation/","excerpt":"Story-timeI saw SquaredUp some year or two ago while googling about on behalf of a customer looking for a dashboard kind of thingy. It looked good and fairly simple, but for some reason it never clicked with the customer and we ended up going for some custom-made dashboards with a little scripting and some DB-queries. I kind of liked the look of their product though and have kept an eye on them now and then.Fast-forward to may 21st this year and the release of version 1.8 and a whole slew of nifty little features. What specifically picked my interest was the linked dashboards, SharePoint integration and the included SLA and Map plugins. This basically ticked a lot of boxes many of my customers have looked for and something we’ve normally been looking into… err… other products for. That, coupled with some new videos on their Youtube-channel, a few well-placed tweets and a little mail-correspondence had me setting it up in my portable little lab. One of the interesting points is how, supposedly easy, it is to set the portal up. So I reset my lab – PDT is just wonderful – and decided to go for the hail-dummy approach. No manual, no preparations, no check-lists… Next-next-next then hopefully a working portal.","keywords":null,"text":"Story-timeI saw SquaredUp some year or two ago while googling about on behalf of a customer looking for a dashboard kind of thingy. It looked good and fairly simple, but for some reason it never clicked with the customer and we ended up going for some custom-made dashboards with a little scripting and some DB-queries. I kind of liked the look of their product though and have kept an eye on them now and then.Fast-forward to may 21st this year and the release of version 1.8 and a whole slew of nifty little features. What specifically picked my interest was the linked dashboards, SharePoint integration and the included SLA and Map plugins. This basically ticked a lot of boxes many of my customers have looked for and something we’ve normally been looking into… err… other products for. That, coupled with some new videos on their Youtube-channel, a few well-placed tweets and a little mail-correspondence had me setting it up in my portable little lab. One of the interesting points is how, supposedly easy, it is to set the portal up. So I reset my lab – PDT is just wonderful – and decided to go for the hail-dummy approach. No manual, no preparations, no check-lists… Next-next-next then hopefully a working portal. The InstallationFirst, download the installation file (yes, singular) through the link you’ve got in your email and save it somewhere proper. Doubleclicked the installation packaged and it now tells me it will install a few pre-requisites and configure the website for me. Next! The EULA I am sure each one of you are reading. Next! Installing, or rather configuring, IIS and pre-requisites for me. Very nice. Next! Quick summary before actual installation. Next! This step actually requires a little action on your part. In this installation, the default setting “localhost” would actually work but I prefer to actually configure these things properly. I only have a single Management Server in this lab, so testing a load-balanced highly available scenario was not possible. Enter Management Server name, then Next! After a slight case of progress-bar the installation is now complete. Click link and exit the installer. Time spent so far is less than ten minutes, probably closer to five.Now it’s time to login using your normal SCOM credentials. First login will bring you to the Activation Screen. Simply paste the activation key from the email and Activate. This requires a working internet connection. That’s it! Well… not really. Navigating the portal I noticed that the spark-lines aren’t showing, and hitting the “View Performance” link on an object view gives me a “Login failed for user…” error. I know I saw something about configuring the Data Warehouse in the email, so I check the blissfully simple Settings panel. Followed the instructions to configure the security of the OperationsManagerDW database for the SquaredUp web application, and that’s really it. Portal is up and running, spark-lines working. Ready to go. ConclusionI wish more products and “add-ons” to SCOM were this easy to install. No extra databases, no extra permissions, no extra infrastructure. I would like to try it out in a larger environment and see what the load on the website, the databases and the data access service will be. It would also be necessary to verify that it works properly when the management servers are behind a load balancer and maybe even putting the SquaredUp portal behind one itself. Since there is not a lot of configuration to be done and no database, it should work. We’ll see. Next up will be fiddling about with custom dashboards, maps, and generally figuring out what else we can do.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Field Notes","slug":"Field-Notes","permalink":"http://stegenfeldt.github.io/tag/Field-Notes/"},{"name":"SquaredUp","slug":"SquaredUp","permalink":"http://stegenfeldt.github.io/tag/SquaredUp/"}]},{"title":"OpsMgr 2012 R2 UR3 - Field Notes [#opsmgr]","slug":"opsmgr2012r2ur3-field-notes","date":"2014-09-02T09:30:18.000Z","updated":"2016-05-19T09:11:09.369Z","comments":true,"path":"opsmgr2012/opsmgr2012r2ur3-field-notes/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/opsmgr2012r2ur3-field-notes/","excerpt":"Quick and unrefined notes on Update Roll-up 3 for System Center 2012 R2 - Operations Manager. PreparationUsual routine, check the KB for instructions and known issues. Double-check with Holman’s blog and take note of any irregularities.Download, curse your favourite deity and re-try in IE. Unpack the CAB-files (why do you keep putting them in CAB-files?) and throw away all the unnecessary language-specific console patches. Notify affected parts of the organisation, I’ve had the benefit to work with good release managers at all clients so far, so no biggie. Then try to close as many consoles as possible to avoid any blocks in database. Make sure you have the credentials for the Data Access service account at hand. Issues - So Far(updated 2014-09-02) The SQL Script for the OpsDW was deadlocked at all sites and customers without exception. It’s easily fixed by stopping the management server services. A few dashboards (the 2012 versions) went blank. Self-healed after some aggregation job over night. From what I’ve noticed, only the SLA Dashboards are affected but never all of them. Agents behind daisy-chained Gateways is not identified as in need of an update. “Repairing” them from the Console is one work-around that seems to work consistently. A few agents that was updated using Windows Update did not report as updated. Repair fixed that nuisance. Had to flush the cache on a few Gateways to avoid heartbeat failures from their agents. Only daisy-chained ones if I recall correctly.","keywords":null,"text":"Quick and unrefined notes on Update Roll-up 3 for System Center 2012 R2 - Operations Manager. PreparationUsual routine, check the KB for instructions and known issues. Double-check with Holman’s blog and take note of any irregularities.Download, curse your favourite deity and re-try in IE. Unpack the CAB-files (why do you keep putting them in CAB-files?) and throw away all the unnecessary language-specific console patches. Notify affected parts of the organisation, I’ve had the benefit to work with good release managers at all clients so far, so no biggie. Then try to close as many consoles as possible to avoid any blocks in database. Make sure you have the credentials for the Data Access service account at hand. Issues - So Far(updated 2014-09-02) The SQL Script for the OpsDW was deadlocked at all sites and customers without exception. It’s easily fixed by stopping the management server services. A few dashboards (the 2012 versions) went blank. Self-healed after some aggregation job over night. From what I’ve noticed, only the SLA Dashboards are affected but never all of them. Agents behind daisy-chained Gateways is not identified as in need of an update. “Repairing” them from the Console is one work-around that seems to work consistently. A few agents that was updated using Windows Update did not report as updated. Repair fixed that nuisance. Had to flush the cache on a few Gateways to avoid heartbeat failures from their agents. Only daisy-chained ones if I recall correctly. PlanningUR3 is like most update roll-ups you’ve seen so far. There’s a bunch of msp files you install on the different server roles, a few SQL-scripts for the OpsDB and the OpsDW and some updated core management packs. I have used the following order and that has worked quite nicely. Management Servers (and locally installed consoles) SQL-Scripts Management Packs1 Consoles2 Gateway Servers2 Web Console2 Agents2 The first management server takes the longest time as it will update the databases as well and you must wait for it to complete before hitting any extra management servers. Otherwise the databases isn’t marked as updated and multiple installations will try to update the same stuff at the same time, and that’s generally bad. I’d recommend to never update more than one management server at the same time, although it is possible. InstallationManagement ServersFairly straight-forward. Run the msp-file for the server update in an administrative command prompt and follow the wizard. First server takes a while (anything from 10-40 minutes depending on management group size and load in my experience). When that’s done, move on to the next management server. If your management servers have multiple roles, like Console, Web Console or Reporting, go ahead and update those at once. SQL-ScriptsThe scripts are unpacked by the setup. You will find them under %SystemDrive%\\Program Files\\System Center 2012 R2\\Operations Manager\\Server\\SQL Script for Update Rollups. Do OpsDW first using the UR_Datawarehouse.sql script, then go for OpsDB using Update_rollup_mom_db.sql. I’ve gotten the deadlock error on all installations so far and the best way to avoid that is to stop the management server services for this part. It’s absolutely crucial to have the scripts run to successful completion before running the next or moving on to any other server roles. ConsoleNothing out of the ordinary here, make sure you run the Console msp in an administrative command prompt. Management PacksThe updated core management packs are unpacked into %SystemDrive%\\Program Files\\System Center 2012 R2\\Operations Manager\\Server\\Management Packs for Update Rollups. Import them using one of the updated consoles. GatewayNext-next-next if running as administrator. Take effort to verify that the agent updates has been distributed into the %SystemDrive%\\Program Files\\System Center Operations Manager\\Gateway\\AgentManagement\\&amp;lt;architecture&amp;gt; folder. If not, copy them from the same folder from any of the management servers. Web ConsoleNo problems so far as long as you run the Web Console msp as administrator. AgentsUpdate them as usual, using “Pending Management”, windows update, manual installation, SCCM or whatever method you usually employ. Agent version will not be updated in the Console, but it will be visible under Monitoring/Operations Manager/Agent Management/Agents by Version. SummaryFairly simple update, the SQL Scripts can catch your off-guard if you do not know about them. Had some issues with Gateways, but it’s a pretty quick update in most environments. Have not experienced any reboots or service outages on updated systems. GLHF! *1. You’re going to need at least one updated console to import the MP-updates.&#160;&#8617;2. These can all be executed in parallel, agents behind Gateways will obviously need to be updated after the gateway.&#160;&#8617; &#8617; &#8617; &#8617;","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Field Notes","slug":"Field-Notes","permalink":"http://stegenfeldt.github.io/tag/Field-Notes/"},{"name":"Update Rollup","slug":"Update-Rollup","permalink":"http://stegenfeldt.github.io/tag/Update-Rollup/"}]},{"title":"Cloudflare as Dynamic DNS [#cloudflare #mikrotik #script]","slug":"cloudflare-dynamic-dns-mikrotik","date":"2014-08-25T11:37:36.000Z","updated":"2016-05-19T09:11:09.361Z","comments":true,"path":"mikrotik/cloudflare-dynamic-dns-mikrotik/","link":"","permalink":"http://stegenfeldt.github.io/mikrotik/cloudflare-dynamic-dns-mikrotik/","excerpt":"I have, for a time, been using CloudFlare for CDN, Optimizations and DNS Management for this and a few other domains. At the same time, I’ve been using DynDNS to provide name resolution to my home network/lab. Browsing around the CloudFlare JSON API I noticed that I can update DNS records through some fairly simple HTTP GET requests, and since the RouterOS (the operating system used by Mikrotiks routerboards) has support for some pretty decent scripting I decided to let my router update CloudFlare for some custom and free dynamic DNS resolution. AttributionMy current script is a modified version of a script developed by Konstantin Antselovich. Original script: http://konstant1n.livejournal.com/9759.html Original Author website: http://konstantin.antselovich.com/ Thanks! What you need RouterOS v6+ for HTTPS support Cloudflare API key, aka “Token”, found at the account page Cloudflare DNS Zone name Cloudflare Record Id (more on that later) Cloudflare subdomain name Name of the external router interface","keywords":null,"text":"I have, for a time, been using CloudFlare for CDN, Optimizations and DNS Management for this and a few other domains. At the same time, I’ve been using DynDNS to provide name resolution to my home network/lab. Browsing around the CloudFlare JSON API I noticed that I can update DNS records through some fairly simple HTTP GET requests, and since the RouterOS (the operating system used by Mikrotiks routerboards) has support for some pretty decent scripting I decided to let my router update CloudFlare for some custom and free dynamic DNS resolution. AttributionMy current script is a modified version of a script developed by Konstantin Antselovich. Original script: http://konstant1n.livejournal.com/9759.html Original Author website: http://konstantin.antselovich.com/ Thanks! What you need RouterOS v6+ for HTTPS support Cloudflare API key, aka “Token”, found at the account page Cloudflare DNS Zone name Cloudflare Record Id (more on that later) Cloudflare subdomain name Name of the external router interface Getting the Record IdTo get the record id of the DNS record you want to update, I used the _rec_load_all_ function of the API. And since I’m a windows admin, I use powershell for that. [powershell]$cfDomain = &quot;homelab&quot;$cfToken = &quot;&lt;your API Key/Token&gt;&quot;$cfZone = &quot;example.com&quot;$cfEmail = &quot;&lt;your CF email address&gt;&quot;$apiLoadAllRecordsURI = &quot;https://www.cloudflare.com/api_json.html?a=rec_load_all&amp;tkn=$cfToken&amp;email=$cfEmail&amp;z=$cfZone&amp;quot;$restRequest = Invoke-RestMethod -Uri $apiLoadAllRecordsURI$restRequest.response.recs.objs | ?{$_.display_name -eq $cfDomain} | fl -Property rec_id,name,display_name,type,ttl,service_mode[/powershell] That should, given that you’ve replaced all the example variables produce something like this: [plain]rec_id : 16606003name : homelab.example.comdisplay_name : homelabtype : Attl : 1service_mode : 0[/plain] And with that done, you should have everything necessary for the RouterOS script. Building the ScriptI’m not going to go into the syntax of ros scripts, but I’ll try to explain the different building block to some degree. Defining our variablesFirst, we’ll define out variables used for the script. The global $hostname variable is actually redundant as I could derive the FQDN from $CFDomain and $CFZone, but it’s used in other scripts in my router so it’s included for that purpose alone. [plain]######## Set and collect general variables #########:global hostname &quot;homelab.example.com&quot;:global resolvedIP &quot;&quot;:global externalIP &quot;&quot;:global WANInterface &quot;eth1-ext-internet&quot; ######## Set CloudFlare variables #################:local CFemail &quot;&lt;same email as in the powershell script&quot;:local CFtkn &quot;&lt;your API key/token&gt;&quot;:local CFzone &quot;example.com&quot;:local CFid &quot;16606003&quot;:local CFtype &quot;A&quot;:local CFttl &quot;1&quot;:local CFservicemode &quot;0&quot;:local CFDomain &quot;homelab&quot;:local CFDebug &quot;true&quot;[/plain] Take care to verify and compare the CFxx variables with the ones used in and received from the previous powershell script, but also the $hostname variable. hostname: Used in the script to lookup the currently set IP-address. WANInterface: The list name of the external interface, used to find the external IP-address. CFemail: Your CloudFlare Login email. CFtkn: Your API Key/Token. CFzone: Your DNS Zone. CFid: The rec_id from the powershell script. CFtype: A for IPv4 host records, AAAA for IPv6. CFttl: Record time-to-live, use “1” for automatic. CFservicemode: Use “0” for direct traffic or “1” to go through their CDN, Optimizations and Security features. I recommend “0” for anything but websites. CFDomain: Subdomain or rather hostname for your router. CFDebug: Use “True” to print some informational stuff to the router logs. Resolve IP-addressesNext, we resolve two IP-addresses. First one, $externalIP, is the routers current external address. And the second, $resolvedIP, is the address currently set for our $hostname. [plain]######## Resolve and set IP-variables ##########:local currentIP [/ip address get [/ip address find interface=$WANInterface ] address];:set externalIP [:pick $currentIP 0 [:find $currentIP &quot;/&quot;]];:set resolvedIP [:resolve $hostname];[/plain] Build CF API Request and log debug infoNow, build the URI for the API call from our variables. [plain]######## Build CF API Url #########################:local CFurl &quot;https://www.cloudflare.com/api_json.html\\3F&amp;quot;:set CFurl ($CFurl . &quot;a=rec_edit&amp;tkn=$CFtkn&amp;id=$CFid&quot;);:set CFurl ($CFurl . &quot;&amp;email=$CFemail&amp;z=$CFzone&amp;type=$CFtype&quot;);:set CFurl ($CFurl . &quot;&amp;name=$CFDomain&amp;service_mode=$CFservicemode&amp;ttl=$CFttl&quot;);[/plain] And if the $CFdebug variable is set to “true”, write a little info to the router log. [plain]######## Write debug info to log #################:if ($CFDebug = &quot;true&quot;) do={:log info (&quot;CF: hostname = $hostname&quot;):log info (&quot;CF: resolvedIP = $resolvedIP&quot;):log info (&quot;CF: currentIP = $currentIP&quot;):log info (&quot;CF: externalIP = $externalIP&quot;):log info (&quot;CF: CFurl = $CFurl&amp;content=$externalIP&quot;)};[/plain] Compare and UpdateLast step is to compare $externalIP with $resolvedIP. If they don’t match, our external IP-address has been changed and we need to update the DNS record. To execute the HTTP GET request we use a RouterOS tool called fetch to which we pass the $CFurl variable. The reason this will not work before RouterOS v6+ is that before that there was no support for HTTPS, and CloudFlare does not accept unencrypted traffic for their APIs. The script block is pretty straight-forward. Compare, update, flush local DNS-cache and write to the log. [plain]######## Compare and update CF if necessary #####:if ($resolvedIP != $externalIP) do={:log info (&quot;CF: Updating CF, setting $CFDomain = $externalIP&quot;)/tool fetch mode=https url=&quot;$CFurl&amp;content=$externalIP&quot; keep-result=no/ip dns cache flush} else={:log info &quot;CF: No Update Needed!&quot;}[/plain] Permissions/PoliciesThis part, I’m not entirely sure on. The script needs to do name resolution, read settings and set variables and it works for me with these policies configured: Read Write Test Sniff SensitiveIt might be over-doing it a bit, but I have not had occasion to fiddle with them yet. SchedulingI have this script scheduled to run once every 20 minutes. As it will only try to update the DNS records if there is a difference between them and the current external IP-address I feel fairly sure that I won’t be tagged as a spammer or something by CloudFlare. The schedule is configured with: Start Time: startup Interval: 00:20:00 On Event: /system script run &lt;Name of your script&gt; Policy: Read,Write, Test, Sniff, SensitiveThis schedule is also a good place for a hairpin update if it’s needed. The Copy-Paste partNow, obviously, at least make sure you proof-read the script before putting it into production. I am not a network dude, and I rarely dabble with ROS scripts. I am certain that anyone with a bit more experience could create a smarter, prettier version of this script, so use at your own risk. Anyway, here’s the script in it’s entirety. [plain] ######## Set and collect general variables #########:global hostname &quot;homelab.example.com&quot;:global resolvedIP &quot;&quot;:global externalIP &quot;&quot;:global WANInterface &quot;eth1-ext-internet&quot; ######## Set CloudFlare variables #################:local CFemail &quot;&lt;same email as in the powershell script&quot;:local CFtkn &quot;&lt;your API key/token&gt;&quot;:local CFzone &quot;example.com&quot;:local CFid &quot;16606003&quot;:local CFtype &quot;A&quot;:local CFttl &quot;1&quot;:local CFservicemode &quot;0&quot;:local CFDomain &quot;homelab&quot;:local CFDebug &quot;true&quot; ######## Resolve and set IP-variables ##########:local currentIP [/ip address get [/ip address find interface=$WANInterface ] address];:set externalIP [:pick $currentIP 0 [:find $currentIP &quot;/&quot;]];:set resolvedIP [:resolve $hostname]; ######## Build CF API Url #########################:local CFurl &quot;https://www.cloudflare.com/api_json.html\\3F&amp;quot;:set CFurl ($CFurl . &quot;a=rec_edit&amp;tkn=$CFtkn&amp;id=$CFid&quot;);:set CFurl ($CFurl . &quot;&amp;email=$CFemail&amp;z=$CFzone&amp;type=$CFtype&quot;);:set CFurl ($CFurl . &quot;&amp;name=$CFDomain&amp;service_mode=$CFservicemode&amp;ttl=$CFttl&quot;); ######## Write debug info to log #################:if ($CFDebug = &quot;true&quot;) do={:log info (&quot;CF: hostname = $hostname&quot;):log info (&quot;CF: resolvedIP = $resolvedIP&quot;):log info (&quot;CF: currentIP = $currentIP&quot;):log info (&quot;CF: externalIP = $externalIP&quot;):log info (&quot;CF: CFurl = $CFurl&amp;content=$externalIP&quot;)}; ######## Compare and update CF if necessary #####:if ($resolvedIP != $externalIP) do={:log info (&quot;CF: Updating CF, setting $CFDomain = $externalIP&quot;)/tool fetch mode=https url=&quot;$CFurl&amp;content=$externalIP&quot; keep-result=no/ip dns cache flush} else={:log info &quot;CF: No Update Needed!&quot;}[/plain] &nbsp;","raw":null,"content":null,"categories":[{"name":"Mikrotik","slug":"mikrotik","permalink":"http://stegenfeldt.github.io/topics/mikrotik/"}],"tags":[{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"},{"name":"DNS","slug":"DNS","permalink":"http://stegenfeldt.github.io/tag/DNS/"},{"name":"Invoke-RestMethod","slug":"Invoke-RestMethod","permalink":"http://stegenfeldt.github.io/tag/Invoke-RestMethod/"},{"name":"Mikrotik","slug":"Mikrotik","permalink":"http://stegenfeldt.github.io/tag/Mikrotik/"},{"name":"RouterOS","slug":"RouterOS","permalink":"http://stegenfeldt.github.io/tag/RouterOS/"}]},{"title":"Quick Demo - Add Windows Performance Collection Rule [#opsmgr, #mpauthoring]","slug":"quick-demo-add-windows-performance-collection-rule-opsmgr-mpauthoring","date":"2013-02-21T08:25:39.000Z","updated":"2016-05-19T09:11:09.354Z","comments":true,"path":"opsmgr2007/opsmgr2012/quick-demo-add-windows-performance-collection-rule-opsmgr-mpauthoring/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/opsmgr2012/quick-demo-add-windows-performance-collection-rule-opsmgr-mpauthoring/","excerpt":"","keywords":null,"text":"By request, I uploaded a short clip demonstrating how you would add a windows performance counter to a performance collection rule using the Authoring Console. It is a fairly simple task to complete but does require the Authoring Console, obviously, and a better target class than what I use in the demo. The demo also assumes that this counter exist on all the targeted servers in your environment. It would be wise, when making your management pack, to check that it’s there on all targeted operating systems, and that’s what I use Performance Monitor for. (just search for perfmon in your start menu or run perfmon.exe) Enjoy.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"OpsMgr 2012","slug":"opsmgr2007/opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/opsmgr2012/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"MP Development","slug":"MP-Development","permalink":"http://stegenfeldt.github.io/tag/MP-Development/"},{"name":"Video","slug":"Video","permalink":"http://stegenfeldt.github.io/tag/Video/"}]},{"title":"OpsMgr 2012 Agent Failover – A Faster Script with Wildcards [#opsmgr, #powershell]","slug":"opsmgr-2012-agent-failover-a-faster-script-with-wildcards-opsmgr-powershell","date":"2012-06-28T12:28:36.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"opsmgr2012/PoSH/opsmgr-2012-agent-failover-a-faster-script-with-wildcards-opsmgr-powershell/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/PoSH/opsmgr-2012-agent-failover-a-faster-script-with-wildcards-opsmgr-powershell/","excerpt":"Now we’re gonna make things even faster! In the previous post on the subject of Agent Fail-over in Operations Manager 2012 we created a script that will go through a selection of agents and make sure that they all have up-to-date fail-over settings. We are doing the same thing in this one, but making it go faster. In my lab, it’s about five times faster in fact and I only have about 20 agents to play with. Not really a big deal, but scale it up a bit and add a few thousand agents and the pay-off will be very significant. As usual, the script will work as is, but it really is more to show the concept. You would have to add filtering to make sure you don’t mix agents behind gateway servers and agents behind management servers. Giving an agent behind a gateway a management servers as it’s fail-over server will likely not help you in any way. We will pretty quickly go “advanced” this time, so buckle up. ;)","keywords":null,"text":"Now we’re gonna make things even faster! In the previous post on the subject of Agent Fail-over in Operations Manager 2012 we created a script that will go through a selection of agents and make sure that they all have up-to-date fail-over settings. We are doing the same thing in this one, but making it go faster. In my lab, it’s about five times faster in fact and I only have about 20 agents to play with. Not really a big deal, but scale it up a bit and add a few thousand agents and the pay-off will be very significant. As usual, the script will work as is, but it really is more to show the concept. You would have to add filtering to make sure you don’t mix agents behind gateway servers and agents behind management servers. Giving an agent behind a gateway a management servers as it’s fail-over server will likely not help you in any way. We will pretty quickly go “advanced” this time, so buckle up. ;) Being a slight modification of the script in the last post I am not going to go through those details. Use that post if you need references to the Inputs, the OpsMgr 2012 Modules, Management Group connection and gathering your agents and management servers. Why Is It Faster?We are doing the same thing, on the same agents and with the same servers. And we already did some optimization by loading them all into memory and working from there. How do you make it faster? Basically, I’m cutting the over-head of the cmdlets and how they work. You may have noticed that in the “Do Stuff” section, we are actually calling the Set-SCOMParentManagementServer cmdlet twice! Once for the primary Management Server and once for the fail-over Management Servers. In effect, we connect, fire a command, wait for result, and disconnect two times for each agent. And pretty much only because the cmdlet does not offer support to set primary and fail-over management servers at the same time. Any attempt to do so will return an ambiguous parameter error. I don’t like that. A brief look at the agent object class, Microsoft.EnterpriseManagement.Administration.AgentManagedComputer, revealed a method called SetManagementServers. This method takes, or actually “requires”, two parameters. One for primary and one for fail-over management servers. Yay! Using this method saves us a bunch of over-head and a couple of round-trips to the SDK-service. The ChallengeUnfortunately, you cannot simply toss an array of management servers at the SetManagementServers method. With a bit of knowledge or keen eyes you will spot the problem right away. I didn’t and was pulling my hair for a while until I realized what caused the errors. Looking closer at how the method is defined we see this: [csharp]public void SetManagementServers ( ManagementServer managementServer, IList failoverManagementServers )[/csharp] You see that IList&lt;ManagementServer&gt; part?That’s the problem. When you run Get-SCOMManagementServer and save the result to a powershell variable, you will get a powershell “Enumerable”. In C#, that would be a class that implements the IEnumerable interface. Sad part is, it does not also implement IList. If you are thinking “IList… IEnumerable… Interface… Whaaaaa…???” right now, don’t worry. You don’t have to understand this to read the script later on, just think of it as different types of data. To get around this, we create a new object based on the dotNET List type and populate it with the management servers in our $scomFailOverMS array. [powershell]$scomMSList = New-Object ‘Collections.Generic.List[Microsoft.EnterpriseManagement.Administration.ManagementServer]’foreach ($scomMS in $scomFailOverMS) { Loop through the array and add your failover MSs to the list $scomMSList.Add($scomMS)}[/powershell] Note:We have to do that foreach loop since our $scomMSList object do not implement IEnumerableStill with me? Configuring the AgentAs the method exist on that AgentManagedComputer class we will call it on our $scomAgent object, like this: [powershell]$scomAgent.SetManagementServers($scomPrimaryMS,$scomMSList)[/powershell] And we’re done! I had some doubt that this would be an improvement at first since we have to create our own objects and run an extra foreach-loop, but as we only work on objects in memory and only speak to the SDK service once per agent, we cut a lot of over-head and delays from our execution. On 20-ish agents in a lab, I’ve measured the execution time drop to barely a fifth. The Copy/Paste PartAnd here’s the entire script with a few added comments for clarity. Read, adapt and try it. In a lab, preferably. [powershell]# Input SCOM Management Server to connect to in this session[string]$inputScomMS = &quot;scomms02.domain.local&quot; Input an existing agent you want to modify[string]$inputTargetAgent = &quot;*.domain.local&quot; Connect to SCOM 2012 Management GroupIf (Get-Module -Name &quot;OperationsManager&quot;) { try { Import-Module -Name &quot;OperationsManager&quot; } catch { echo &quot;Could not load Operations Manager module&quot; exit }}New-SCOMManagementGroupConnection -ComputerName $inputScomMS END$scomAgents = Get-SCOMAgent -DNSHostName $inputTargetAgent | Where {$_.ManuallyInstalled -ne $true} Get all of the management serversIt is ofcourse possible to search by hostname and wildcards using selectedparameters to the cmdlet.$scomManagementServers = Get-SCOMManagementServer Switch to the following line to only get Gateway Servers#$scomManagementServers = Get-SCOMGatewayManagementServerforeach ($scomAgent in $scomAgents) { # Get the primary management server for the agent $scomPrimaryMS = $scomManagementServers | where {$_.Name -eq $scomAgent.PrimaryManagementServerName} # Remove the primary MS from &amp;quot;all MS&amp;quot; array to use it for FailOver servers $scomFailOverMS = $scomManagementServers | where {$_.Name -ne $scomPrimaryMS.Name} # Create a new IList derived object for the failover MSs # You have to do this because the SetManagementServers() method requires an # IList and the MS-array is an IEnumerable type. So we basically create # a new IList object och the ManagementServer type. $scomMSList = New-Object &apos;Collections.Generic.List[Microsoft.EnterpriseManagement.Administration.ManagementServer]&apos; foreach ($scomMS in $scomFailOverMS) { # Loop through the array and add your failover MSs to the list $scomMSList.Add($scomMS) } $scomAgent.SetManagementServers($scomPrimaryMS,$scomMSList) }[/powershell] GLHF!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"},{"name":"PoSH","slug":"opsmgr2012/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/PoSH/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"},{"name":"Fail-over","slug":"Fail-over","permalink":"http://stegenfeldt.github.io/tag/Fail-over/"}]},{"title":"OpsMgr 2012 Agent Failover - Simple Script with Wildcards [#opsmgr, #powershell]","slug":"opsmgr-2012-agent-failover-simple-script-with-wildcards-opsmgr-powershell","date":"2012-06-21T08:58:13.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"opsmgr2012/PoSH/opsmgr-2012-agent-failover-simple-script-with-wildcards-opsmgr-powershell/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/PoSH/opsmgr-2012-agent-failover-simple-script-with-wildcards-opsmgr-powershell/","excerpt":"In the last post, OpsMgr 2012 Agent &amp; Gateway Failover – The Basics, we looked at the basics of the Agent and Gateway fail-over configuration cmdlets and how to use them in a direct and interactive setting. This is absolutely useful when you got this specific agent that you need to configure with a specific fail-over management server. To spice it up a little, we are going to add a little intelligence to it and enable wild-card selections while at it. The scenario we are building this script for is that now and then you want to make sure that certain agents have fail-over management servers configured. You also want to make sure that all management servers that are not the primary management server of any selected agent will be in that list of fail-over servers. This would include any new management servers as well as exclude any removed ones. In short, make sure your agent fail-over settings are up-to-date with the current environment.","keywords":null,"text":"In the last post, OpsMgr 2012 Agent &amp; Gateway Failover – The Basics, we looked at the basics of the Agent and Gateway fail-over configuration cmdlets and how to use them in a direct and interactive setting. This is absolutely useful when you got this specific agent that you need to configure with a specific fail-over management server. To spice it up a little, we are going to add a little intelligence to it and enable wild-card selections while at it. The scenario we are building this script for is that now and then you want to make sure that certain agents have fail-over management servers configured. You also want to make sure that all management servers that are not the primary management server of any selected agent will be in that list of fail-over servers. This would include any new management servers as well as exclude any removed ones. In short, make sure your agent fail-over settings are up-to-date with the current environment. InputsTo use this script you need to know which management server you should connect your powershell session to and which agent, or agents, you want to check and configure. [powershell] Input SCOM Management Server to connect to in this session[string]$inputScomMS = &quot;scomms01.domain.local&quot; Input an existing agent you want to modify[string]$inputTargetAgent = &quot;*.domain.local&quot; [/powershell] Note: If you are using load-balanced SDK-services, or “Data Access Services”, pointing $inputScomMS to that virtual host-name will work perfectly fine.This example uses a wild-card for the agent selection and I guess it’s the most likely scenario for this script, but a single host-name obviously works fine as well. Supported wildcard selections are documented at TechNet. An array of computer-names or a comma-separated list, however, will not work. You could easily add that functionality but it’s out of scope for this example. Connect to Your Management GroupTo run any script against an Operations Manager 2012 Management Group we need a connection to one. To connect to a management group we have to load the OperationsManager module. Lets check for a loaded module, load it if necessary and connect to the Management Server from the $inputScomMS setting. If loading the module fails–maybe it is not installed–we will exit the script. [powershell] Check if OperationsManager module is loadedIf (Get-Module -Name &quot;OperationsManager&quot;) { try { Try to load the module Import-Module -Name &quot;OperationsManager&quot; } catch { Did not work, exit the script echo &quot;Could not load Operations Manager module&quot; exit }} Module is loaded, connect to Management Group/ServerNew-SCOMManagementGroupConnection -ComputerName $inputScomMS [/powershell] A good idea would, of course, be to first check if we already have an existing management group connection before creating a new one. But that’s up to you. Rally Your Agents (and Management Servers)Since we cannot manage manually installed agents–that would be AD-integrated or installed locally using Configuration Manager or maybe the wizard–through powershell we don’t even want to try. So we’ll exclude them. We also need all the available management servers. This will not handle Gateway servers as they have their own cmdlet, Get-SCOMGatewayManagementServer, in Operations Manager 2012. Strike that! There is a specific cmdlet for Gateway Servers in OpsMgr 2012, but the regular Get-SCOMManagementServer actually don’t care whether it’s a normal Management Server or a Gateway Server. The Get-SCOMGatewayManagementServer, however, only return real Gateway Servers. That means that this script will not care if it is a Management Server or a Gateway Server, so be sure to add some kind of filtering before running it in a Management Group containing management servers. [powershell] Select matching remotely manageable agents$scomAgents = Get-SCOMAgent -DNSHostName $inputTargetAgent | Where {$_.ManuallyInstalled -ne $true} Get all management servers$scomManagementServers = Get-SCOMManagementServer [/powershell] The reason I like to store all matching agents in a variable is that we will save ourselves a lot of trips to the Data Access Service later on, and we also get a nice collection to run our foreach-loop on. This method is much faster than running Get-SCOMAgent inline as we did in “The Basics”. Note: It would probably be a good idea to check that $scomAgents actually contains anything; checking for $null with a simple _if() _would be enough. Do StuffWe have our connection to the management group, we have collected our agents, and we have our management servers. It’s time to loop through the agents and set their Primary and Fail-over management servers. [powershell] foreach ($scomAgent in $scomAgents) { Get the primary management server for the agent $scomPrimaryMS = $scomManagementServers | where {$_.Name -eq $scomAgent.PrimaryManagementServerName} Remove the primary MS from &quot;all MS&quot; array to use it for FailOver servers $scomFailOverMS = $scomManagementServers | Where-Object {$_.Name -ne $scomPrimaryMS.Name} Set Primary Management Server Set-SCOMParentManagementServer -Agent $scomAgent -PrimaryServer $scomPrimaryMS Set Fail-over Management Server Set-SCOMParentManagementServer -Agent $scomAgent -FailoverServer $scomFailOverMS} [/powershell] The nice thing about loading the agents and the management servers into variables is that all the information you need for this script is pre-cached in memory. You don’t have to connect to the management group to find out which management server happens is the primary for each agent. And you don’t have to run Get-SCOMManagementServer for each agent to select which ones that will be fail-over management servers. All that information is in memory, and memory is fast. The Copy/Paste PartAs usual, here’s the entire script for you to copy. Read it, try it, adapt it… [powershell] Input SCOM Management Server to connect to in this session[string]$inputScomMS = &quot;scomms02.domain.local&quot; Input an existing agent you want to modify[string]$inputTargetAgent = &quot;*.domain.local&quot; Connect to SCOM 2012 Management GroupCheck if OperationsManager module is loadedIf (Get-Module -Name &quot;OperationsManager&quot;) { try { Try to load the module Import-Module -Name &quot;OperationsManager&quot; } catch { Did not work, exit the script echo &quot;Could not load Operations Manager module&quot; exit }} Module is loaded, connect to Management Group/ServerNew-SCOMManagementGroupConnection -ComputerName $inputScomMS ENDSelect matching remotely manageable agents$scomAgents = Get-SCOMAgent -DNSHostName $inputTargetAgent | Where {$_.ManuallyInstalled -ne $true} Get all management servers$scomManagementServers = Get-SCOMManagementServerforeach ($scomAgent in $scomAgents) { Get the primary management server for the agent $scomPrimaryMS = $scomManagementServers | where {$_.Name -eq $scomAgent.PrimaryManagementServerName} Remove the primary MS from &quot;all MS&quot; array to use it for FailOver servers $scomFailOverMS = $scomManagementServers | Where-Object {$_.Name -ne $scomPrimaryMS.Name} Set Primary Management Server Set-SCOMParentManagementServer -Agent $scomAgent -PrimaryServer $scomPrimaryMS Set Fail-over Management Server Set-SCOMParentManagementServer -Agent $scomAgent -FailoverServer $scomFailOverMS} Done![/powershell] GLHF!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"},{"name":"PoSH","slug":"opsmgr2012/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/PoSH/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Fail-over","slug":"Fail-over","permalink":"http://stegenfeldt.github.io/tag/Fail-over/"}]},{"title":"Menu Problems!","slug":"menu-problems","date":"2012-06-21T06:01:50.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"tb/menu-problems/","link":"","permalink":"http://stegenfeldt.github.io/tb/menu-problems/","excerpt":"","keywords":null,"text":"The menus are looking a bit off as you may have noticed. I guess it’s an issue with WordPress 3.4 and Superfish and are trying to figure out where it goes haywire. Sorry for the inconvenience. Update!I switched the theme to at least get the navigation working while I try to figure out what the problem with the regular theme is.","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[{"name":"Teknoglot","slug":"Teknoglot","permalink":"http://stegenfeldt.github.io/tag/Teknoglot/"}]},{"title":"OpsMgr 2012 Agent & Gateway Failover - The Basics [#opsmgr, #powershell]","slug":"opsmgr-2012-agent-gateway-failover-the-basics","date":"2012-05-30T12:12:37.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"opsmgr2012/PoSH/opsmgr-2012-agent-gateway-failover-the-basics/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/PoSH/opsmgr-2012-agent-gateway-failover-the-basics/","excerpt":"I have previously posted a few scripts on managing and configuring fail-over management servers on gateways and agents in System Center Operations Manager 2007 R2. Now that System Center 2012 Operations Manager is RTM and users are starting to explore the differences between the versions I see more and more questions on how you do, in OpsMgr 2012, what you did in OpsMgr 2007. In a few posts henceforth I will go through Agent and Gateway server fail-over configuration and management. In this first post I’ll look at the very basics of fail-over configuration, the cmdlets to use and some one-liners.","keywords":null,"text":"I have previously posted a few scripts on managing and configuring fail-over management servers on gateways and agents in System Center Operations Manager 2007 R2. Now that System Center 2012 Operations Manager is RTM and users are starting to explore the differences between the versions I see more and more questions on how you do, in OpsMgr 2012, what you did in OpsMgr 2007. In a few posts henceforth I will go through Agent and Gateway server fail-over configuration and management. In this first post I’ll look at the very basics of fail-over configuration, the cmdlets to use and some one-liners. The cmdletFirst of all, the cmdlets of OpsMgr powershell have all got new names looking like Verb-SCOMnoun and to list them all in the console you can execute the following command: [powershell]get-command SCOM[/powershell] The cmdlet we are looking for to set and manage primary and fail-over management servers is [powershell]Get-SCOMParentManagementServer[/powershell] As usual, you can pass the cmdlet as a parameter to get-help for information about its parameters and a few use-cases. SYNOPSIS Changes the primary and failover management servers for an agent or gateway management server. SYNTAX Set-SCOMParentManagementServer -Agent -PrimaryServer [-PassThru ] [-Confirm ] [-WhatIf ] [] Set-SCOMParentManagementServer -Agent -FailoverServer [-PassThru ] [-Confirm ] [-WhatIf ] [] Set-SCOMParentManagementServer -GatewayServer -FailoverServer [-PassThru ] [-Confirm ] [-WhatIf ] [] Set-SCOMParentManagementServer -GatewayServer -PrimaryServer [-PassThru] [-Confirm] [-WhatIf] []But that’s so boring to read the manual is a bit sketchy on how it behaves and the limitations. The One-Liners!I have compiled a few examples for a few common tasks to better illustrate it’s uses. Set Primary Management Server on Agent[powershell] #Set Primary Management Server on AgentSet-SCOMParentManagementServer -Agent (Get-SCOMAgent -DNSHostName &quot;AGENT.domain.local&quot;) -PrimaryServer (Get-SCOMManagementServer -Name &quot;SCOMMS01.domain.local&quot;) [/powershell] Set Fail-over Management Server on Agent[powershell] #Set Fail-over Management Server on AgentSet-SCOMParentManagementServer -Agent (Get-SCOMAgent -DNSHostName &quot;AGENT.domain.local&quot;) -FailoverServer (Get-SCOMManagementServer -Name &quot;SCOMMS02.domain.local&quot;) [/powershell] Set Primary Management Server on Gateway[powershell] #Set Primary Management Server on GatewaySet-SCOMParentManagementServer -GatewayServer (Get-SCOMGatewayManagementServer -Name &quot;SCOMGW01.domain.local&quot;) -PrimaryServer (Get-SCOMManagementServer -Name &quot;SCOMMS01.domain.local&quot;) [/powershell] Set Fail-over Management Server on Gateway[powershell] #Set Fail-over Management Server on GatewaySet-SCOMParentManagementServer -GatewayServer (Get-SCOMGatewayManagementServer -Name &quot;SCOMGW01.domain.local&quot;) -FailoverServer (Get-SCOMManagementServer -Name &quot;SCOMMS02.domain.local&quot;) [/powershell] A few reflectionsAs you may notice, if you have used the OpsMgr 2007 Set-ManagementServer cmdlet you actually have to use separate parameters depending on whether you are configuring management servers on an agent or a gateway server. You probably also noticed that to get an object for a gateway server you also have to use Get-SCOMGatewayManagementServer in OpsMgr 2012. For some reason, there’s different properties on agent objects compared to management and gateway servers. On an MS or GW, you use -Name to select by name, while on an agent you have to use -DNSHostName. Both of these parameters take wild-cards making it possible to find all the agents named “*.domain.local”. While -PrimaryServer only takes a single object the -Agent, -GatewayServer and -FailoverServer can take an array or collection of objects. One more “gotcha” I ran into is the fact that trying to set both -PrimaryServer and -FailoverServer in the same command will fail with an “AmbiguousParameterSet” error. You have to run it once for the Primary Management Server and once for your Fail-over Management Servers. Related SnippetsApart from setting your management servers you might also want to read your agent’s current configuration as well. Get current Primary Management Server on Agent[powershell] #Get current Primary MS on Agent$agent = Get-SCOMAgent -DNSHostName &quot;AGENT.domain.local&quot;$primaryMS = $agent.GetPrimaryManagementServer()write-host &quot;Current Primary ManagementServer: &quot;$primaryMS.Name [/powershell] Get current Failover Management Server on Agent[powershell] #Get current Failover MS on Agent$agent = Get-SCOMAgent -DNSHostName &quot;AGENT.domain.local&quot;$failoverMSs = $agent.GetFailoverManagementServers()write-host &quot;Got&quot;$failoverMSs.Count&quot;failover Management Servers&quot;foreach($failoverMS in $failoverMSs) { $failoverMS.Name} [/powershell] I think that would be all for this post. Next one will touch on a little more intelligence and a few ways to automatically select “other” management servers as fail-over management servers. Enjoy!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"},{"name":"PoSH","slug":"opsmgr2012/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/PoSH/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"Fail-over","slug":"Fail-over","permalink":"http://stegenfeldt.github.io/tag/Fail-over/"},{"name":"Scripts","slug":"Scripts","permalink":"http://stegenfeldt.github.io/tag/Scripts/"}]},{"title":"Load-balanced SCOM2012 SDK Services for Network Illiterates [#opsmgr, #nlb]","slug":"load-balanced-scom2012-sdk-services-for-network-illiterates-opsmgr-nlb","date":"2012-05-18T11:16:51.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"opsmgr2012/load-balanced-scom2012-sdk-services-for-network-illiterates-opsmgr-nlb/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2012/load-balanced-scom2012-sdk-services-for-network-illiterates-opsmgr-nlb/","excerpt":"PreludeNow that System Center Operations Manager no longer has that pesky Root Management Server role; a server role that in larger environments quickly became the choking point and made creating a fully Highly Available SCOM-environment both complex and frustrating to support and with little gain at that. With that gone and the SDK Service, or Data Access Service, thriving on all the Management Servers HA suddenly became pretty simple. All you have to do in SCOM2012 to make sure your management groups keep on kicking is to have at-least two Management Servers and your databases clustered. This new distributed architecture does not only give easy HA, it also makes it possible to connect to the SDK-service—be it using the Operations Console or powershell to name two options—on any Management Server. This, in turn, provides for a completely new level of scalability. Choked on sessions? Deploy a new Management Server! Anyway… given all this scalability and HA, would it not be nice if you could load-balance all these SDK-sessions you will be running from System Center Virtual Machine Manager, System Center Service Manager, System Center Orchestrator, regular scheduled powershell scripts and what-not? Of course it would! And you can! The simple solution is to use the built-in Network Load Balancer (NLB for short) feature in Windows Server and that’s what we’re going to discuss in this post.Before we go, I’d like to point to a great article written by Justin Cook that is covering most bases but in a less for-dummies way. So, yeah… I suppose this is the for-dummies version then. ;) Enjoy!","keywords":null,"text":"PreludeNow that System Center Operations Manager no longer has that pesky Root Management Server role; a server role that in larger environments quickly became the choking point and made creating a fully Highly Available SCOM-environment both complex and frustrating to support and with little gain at that. With that gone and the SDK Service, or Data Access Service, thriving on all the Management Servers HA suddenly became pretty simple. All you have to do in SCOM2012 to make sure your management groups keep on kicking is to have at-least two Management Servers and your databases clustered. This new distributed architecture does not only give easy HA, it also makes it possible to connect to the SDK-service—be it using the Operations Console or powershell to name two options—on any Management Server. This, in turn, provides for a completely new level of scalability. Choked on sessions? Deploy a new Management Server! Anyway… given all this scalability and HA, would it not be nice if you could load-balance all these SDK-sessions you will be running from System Center Virtual Machine Manager, System Center Service Manager, System Center Orchestrator, regular scheduled powershell scripts and what-not? Of course it would! And you can! The simple solution is to use the built-in Network Load Balancer (NLB for short) feature in Windows Server and that’s what we’re going to discuss in this post.Before we go, I’d like to point to a great article written by Justin Cook that is covering most bases but in a less for-dummies way. So, yeah… I suppose this is the for-dummies version then. ;) Enjoy! PrerequisitesWe need to have the Network Load Balancing feature installed on all our targeted Management servers. The quick way to do this is using command-line (Windows Server 2008 R2 or later?). [plain]dism /online /enable-feature /featurename:NetworkLoadBalancingFullServer [/plain] You also need a plan and some information about your new cluster. Make sure you have identified the following parameters before starting the configuration: A Dedicated Cluster IP-Address: A Dedicated Cluster DNS Name: A list of SCOM2012 Management Servers: You can use this pre-flight table to take note of your IP-address, DNS Name and Server List. Create a New ClusterOpen the Network Load Balancing Manager and create a new cluster. In the “New Cluster” dialogue, connect to one of your Management Servers. Enter the name of a management server Click Connect Select the network interface to use Click NextSelect the settings on your first host in the cluster. Make sure it’s the correct IP-address. Click NextSet the Cluster IP-address. Click Add Enter your Dedicated Cluster IP-Address and Subnet mask Click OK Click NextIf need additional IP-addresses, like an IPv6 address, you simply repeat step 1-3 before proceeding to step 4. Edit DNS Names and Cluster Operation Mode. Select your Dedicated Cluster IP-address Enter your chosen Dedicated Cluster DNS Name Select Multicast mode Click Next Note: We are not going to delve into the Cluster Operation Mode in this guide, but this is what I use for Operations Manager 2012. If you want to learn more about these settings, here’s the KB on the various settings: http://support.microsoft.com/kb/323437Set your Port Rules and Affinity Settings. Verify that Affinity is set to “Single”. If not, Click “Edit…” and adjust. Click Finish Note: “Single” affinity tells the cluster to always direct the same client to the same host if possible. This is required to be able to support sessions. In the world of NLB, a “client” is an IP-address. Post-ConfigurationNow that you have a cluster configured you have to make sure your SDK-clients are able to resolve the dedicated cluster DNS-name. The one you picked in the pre-flight table. To enable name resolution you have to add your cluster DNS-name to your DNS-zone and point it to your dedicated cluster IP-address. Make it an A-record and it should work. If you intend to use the cluster name from outside the local network or subnet—Operation Consoles or Powershell sessions for example—you would also need to verify that the router is able to handle the multicast packages. I am by no means a network guy, but asking the person behind that “Don’t blame the network” sign to help you access a NLB cluster on network _X _from network Y usually works. One way to troubleshoot this is to ping the cluster DNS-name from one of the hosts. If that works but you are still unable to ping from another network or subnet, then it might be a router setting. Adding Hosts to the ClusterWith the cluster configured and up-and-running you need to add the rest of the Management Servers. Repeat this section for each Management Server you wish to add to the load-balancing cluster. In the Network Load Balancing Manager, right-click your cluster and select “Add Host To Cluster”. Connect to your next Management Server to be added Enter the server name of the Management Server (“host” in cluster terminology) Click Connect Select the IP-address of the host Click NextVerify your Host Parameters Doublecheck the IP-address Click NextVerify the Port Rules Make sure that Load is Equal and Affinity is Single Click Finish Final VerificationAfter each added host it would be proper to check if it was added correctly. The easiest way is to check their statuses in the Network Load Balancing Manager. Green is generally considered good and you want your hosts to be “Converged”. Another way to verify functionality is to point your Operations Manager console to the Cluster DNS-name instead and connect. If you are in a lab or in an environment where it is OK to shut down Management Servers you could try that as well. Considering my note on routers in the Cluster Post-Configuration I guess it would be prudent to point out that you should try launching SDK-sessions from all networks you intend to connect from. Just to make sure that your routers are correctly configured to handle these kinds of sessions. PostludeNow; as easy this may be I would personally argue that you should involve your network team before starting to deploy your load-balanced clusters. A little heads-up is always a good thing—I have noticed that network people rarely like surprises—and they might actually be able to help you all the way is you ask nicely. And maybe they’ll tell you right away that some configuration is required before-hand instead of giggling frantically in a corner at your feeble attempts to troubleshoot your fresh little cluster. Soooo… have fun! And remember; with great powers come great responsibility. [Sheesh! This post got out of hand!]","raw":null,"content":null,"categories":[{"name":"OpsMgr 2012","slug":"opsmgr2012","permalink":"http://stegenfeldt.github.io/topics/opsmgr2012/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"Highly-Available","slug":"Highly-Available","permalink":"http://stegenfeldt.github.io/tag/Highly-Available/"},{"name":"NLB","slug":"NLB","permalink":"http://stegenfeldt.github.io/tag/NLB/"},{"name":"Tutorial","slug":"Tutorial","permalink":"http://stegenfeldt.github.io/tag/Tutorial/"}]},{"title":"Quick-Hack: Send SMS through Powershell [#powershell]","slug":"quick-hack-send-sms-through-powershell-powershell","date":"2012-05-15T13:14:00.000Z","updated":"2016-05-19T09:11:09.330Z","comments":true,"path":"PoSH/quick-hack-send-sms-through-powershell-powershell/","link":"","permalink":"http://stegenfeldt.github.io/PoSH/quick-hack-send-sms-through-powershell-powershell/","excerpt":"Decided to do a quick-hack/fast-publish on this one as I have had a bit less time to create a nice clean production-ready version as of yet… and people has been asking about how far off the article is. What this script does is to send a text message using a GSM/GPRS modem connected to a local (or LAN-connected with local drivers) serial port using Powershell. Disclaimer!This script “works” but is not fit for production. See it as an example of the general concept to evolve and adapt into something worthy of production use. What’s missing in the latest iteration is: A working Event-Handler to deal with asynchronous call-backs. Support for AT+MSGW (write to modem memory) Reusing messages in modem memory for multiple recipients. Various error- and exeption-handlers. Actually verifying that the modem is AT-capable. Querying the system for available modems and their ports.","keywords":null,"text":"Decided to do a quick-hack/fast-publish on this one as I have had a bit less time to create a nice clean production-ready version as of yet… and people has been asking about how far off the article is. What this script does is to send a text message using a GSM/GPRS modem connected to a local (or LAN-connected with local drivers) serial port using Powershell. Disclaimer!This script “works” but is not fit for production. See it as an example of the general concept to evolve and adapt into something worthy of production use. What’s missing in the latest iteration is: A working Event-Handler to deal with asynchronous call-backs. Support for AT+MSGW (write to modem memory) Reusing messages in modem memory for multiple recipients. Various error- and exeption-handlers. Actually verifying that the modem is AT-capable. Querying the system for available modems and their ports. The ScriptSo, a short note before digging into the script. Prerequisites for this script is that you have identified which COM-port to use and it’s supported baud-rates and whether it supports DTR or not. If you do not know what the hell I am talking about, you could probably have it work with my preconfigured settings anyway. If you are unsure about if your modem supports AT commands you could open a serial connection to the modem using Hyperterminal or PuTTY and run AT+CMGF=1. If supported, the return should be OK. If it is not supported (you get ERROR instead) you would have to use PDU-mode which require a bit of hex-encoding of your messages. This is nothing I have had to do yet and will not be including in this script. Maybe in the future. Maybe. So, looking a some powershelling then. First thing would be to connect to the modem. [ps] Create your instance of the SerialPort Class$serialPort = new-Object System.IO.Ports.SerialPort Set various COM-port settings$serialPort.PortName = &quot;COM1&quot;$serialPort.BaudRate = 19200$serialPort.WriteTimeout = 500$serialPort.ReadTimeout = 3000$serialPort.DtrEnable = &quot;true&quot; Open the connection$serialPort.Open()[/ps] With the connection established, you the set to modem in AT-mode and start sending the message to the modem. [ps] Tell the modem you want to use AT-mode$serialPort.Write(&quot;AT+CMGF=1rn&quot;) Start feeding message data to the modemBegin with the phone number, internationalstyle and a &lt;CL&gt;… that’s the rn part$serialPort.Write(&quot;AT+CMGS=&amp;quot;+46888888888&quot;rn&quot;) Now, write the message to the modem$serialPort.Write(&quot;This is a test!rn&quot;) Send a Ctrl+Z to end the message.$serialPort.Write($([char] 26))[/ps] As you may notice, the message is only stored in the modems memory until you send a Ctrl+z which will end the message and send it. It is possible to add more text to the message before sending it if you would like. Personally, I prefer to store the message into a regular powershell variable and pass that one to the script. The SerialPort library is sort of clever and a local phone number will probably work. For safety, I always use international number with country code as it will work every time. Only thing left now is to close the serial port connection and end the script. Like this. [ps]$serialPort.Close()[/ps] The Copy/Paste part…Here’s the entire script with some added control-features and check to avoid trying to send text messages with no serial connection. [ps] DISCLAIMERThis script is a quick-hack to demonstratethe basics of sending an SMS using an AT-compatible GSM modem connected a localserial port through PowerShell.No error-handling is implemented and thisis NOT a script fit for production.################## Create your instance of the SerialPort Class$serialPort = new-Object System.IO.Ports.SerialPort Set various COM-port settings$serialPort.PortName = &quot;COM1&quot;$serialPort.BaudRate = 19200$serialPort.WriteTimeout = 500$serialPort.ReadTimeout = 3000$serialPort.DtrEnable = &quot;true&quot; Open the connection$serialPort.Open() Add variables for phone number and the message.$phoneNumber = &quot;+46888888888&quot;$textMessage = &quot;This is a test message!&quot; try { $serialPort.Open()}catch { Wait for 5s and try againTold you this is a quick-hack, right? Start-Sleep -Seconds 5 $serialPort.Open()}If ($serialPort.IsOpen -eq $true) { Tell the modem you want to use AT-mode $serialPort.Write(&quot;AT+CMGF=1rn&quot;) Start feeding message data to the modemBegin with the phone number, internationalstyle and a &lt;CL&gt;… that’s the rn part $serialPort.Write(&quot;AT+CMGS=&amp;quot;$phoneNumber&quot;rn&quot;) Give the modem some time to react… Start-Sleep -Seconds 1 Now, write the message to the modem $serialPort.Write(&quot;$textMessagern&quot;) Send a Ctrl+Z to end the message. $serialPort.Write($([char] 26)) Wait for modem to send it Start-Sleep -Seconds 1} Close the Serial Port connection$serialPort.Close()if ($serialPort.IsOpen -eq $false) { echo &quot;Port Closed!&quot;} That’s all folksNow, add call-backs, event-handlers, and return-message handling.[/ps] Enjoy!","raw":null,"content":null,"categories":[{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/topics/PoSH/"}],"tags":[{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"GSM","slug":"GSM","permalink":"http://stegenfeldt.github.io/tag/GSM/"},{"name":"Quick-hack","slug":"Quick-hack","permalink":"http://stegenfeldt.github.io/tag/Quick-hack/"},{"name":"SMS","slug":"SMS","permalink":"http://stegenfeldt.github.io/tag/SMS/"}]},{"title":"Rant - The Concept of Booth-Babes","slug":"rant-the-concept-of-booth-babes","date":"2012-05-08T16:18:05.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"tb/rant-the-concept-of-booth-babes/","link":"","permalink":"http://stegenfeldt.github.io/tb/rant-the-concept-of-booth-babes/","excerpt":"Having visited a few conferences in the last years I have spotted a trend I didn’t think I would see in the IT-Pro sphere. You could probably call me naïve for that but logically we should not encourage this trend. This is my appeal to all exhibitors of future conferences to re-evaluate the concept of booth-babes. I will not go into the genus-political part of this discussion as of now–others are more eloquent and fit to handle that–but rather some of the more pragmatic sides to ditch the BB (short for Booth-Babe) and how that would gain us visitors as well as the exhibitors. I will also keep a pretty frank, and perhaps impolite, tone in this rant of mine. So, here’s my top reasons, in no particular order, to give up the BBs.","keywords":null,"text":"Having visited a few conferences in the last years I have spotted a trend I didn’t think I would see in the IT-Pro sphere. You could probably call me naïve for that but logically we should not encourage this trend. This is my appeal to all exhibitors of future conferences to re-evaluate the concept of booth-babes. I will not go into the genus-political part of this discussion as of now–others are more eloquent and fit to handle that–but rather some of the more pragmatic sides to ditch the BB (short for Booth-Babe) and how that would gain us visitors as well as the exhibitors. I will also keep a pretty frank, and perhaps impolite, tone in this rant of mine. So, here’s my top reasons, in no particular order, to give up the BBs. Reason #1 - BBs is disrupting the purpose of the exhibitionWhen I go to a conference, I am there for the tech, to network and shake paws with the people I collaborate with on-line. It is also a good place to meet the actual corporations that I do business with and discuss their products between four eyes.I do not want to plow through a crowd of great white whales [Oops! I meant “males”] ogling the BBs to get to someone with actual knowledge about the products and solutions at hand. Reason #2 - BBs are alienating the visitorsIf you are a heterosexual male or a homosexual female, the BBs can actually make you embarrassed, shy and unwilling to approach the exhibitor for that sole reason.If you are not, you might find an exhibitor with BBs appalling and take another route for that sole reason. Reason #3 - BBs are intimidating the female visitorsThere is, of course, exceptions to this, but I actually discussed this matter with a couple of gentlewomen in the alumni lounge and they did say that they are both appalled and intimidated to the slightly clad BBs at one particular booth at this years MMS. They even used terms like “ridiculous” and “waste of space” to describe the phenomena.Now, I believe I can hear some of you readers thinking “what? Nice addition to the boring screens and …”. But imaging the opposite for a while. Imagine a whole bunch of Booth-Hunks instead. You know, Brad Pitt in Fight Club and the likes. I know I would be intimidated by that kind of display. Reason #4 - BBs makes it hard to know who to talk toBecause of the BBs, it can at time be hard to know if the lady at the booth just happen to be a nice-looking knowledgeable tech-specialist or simply someone there for eye-candy. Too many times have I had a conversation like this: “Hi! So, tell me about [SystemX]. It looks kinda interesting on paper.” “Hi! Uh, oh! Yeah! You should probably be talking to that guy over there. I don’t really know anything about their stuff.”I hate it. I want to be able to pick anyone in the booth and get a cohesive answer. You cannot be expert on everything and some people are more marketing focused, but at least they can give you the big picture before calling some techy fellow. Last year I had a really nice discussion with a nice lady from EMC that later led to get access to to some beta code. Unfortunately, I had by then grown tired of the BBs and merely approached her since there were lines to the male exhibitors. Which brings me to… Reason #5 - Having BBs is disrespecting your female colleagues.There you are. You most certainly have some very talented women in your development teams–my experience is that’s where you’ll find most of them, as architects and lead developers–but for some reason your decide to hire a bunch of BBs to “spice it up a little”, “draw a little crowd”, “get the attention” and so forth. Do you really think your female colleagues appreciate that? Isn’t that diminishing their talent a bit? I am sure that those who attend conferences for technical reasons and to do a bit of networking would take a nice technical discussion with anyone, however geeky she/he might be, rather than side-stepping a crowd or some figure-head on my way there. I don’t know. Maybe I am alone in this matter, but I’d really like to see this change. I would really like to see vendors and exhibitors trying to dazzle the visitors with great displays, clever uses of software and mind-blowing products and not scantily clad women. Ah, well. Thanks for your time.","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[{"name":"Rant","slug":"Rant","permalink":"http://stegenfeldt.github.io/tag/Rant/"},{"name":"Conference","slug":"Conference","permalink":"http://stegenfeldt.github.io/tag/Conference/"}]},{"title":"Parameter Replacement in AlertName","slug":"parameter-replacement-in-alertname","date":"2012-04-09T20:04:48.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"opsmgr2007/parameter-replacement-in-alertname/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/parameter-replacement-in-alertname/","excerpt":"…and why you should not use it.[tab name=”A Disclimer”] A DisclaimerI have had serious doubts about actually writing this article for almost a year now for reasons that I will explain further on. But as others have discovered this “feature” as well–maybe “hack” would be a better name for it–I feel the need to explain how it works and also why you should not use it. Knowledge is power, and even if I advice against using this technique it is also a good way to understand how SCOM uses display-strings in management packs. [/tab][tab name=”The Good News”]","keywords":null,"text":"…and why you should not use it.[tab name=”A Disclimer”] A DisclaimerI have had serious doubts about actually writing this article for almost a year now for reasons that I will explain further on. But as others have discovered this “feature” as well–maybe “hack” would be a better name for it–I feel the need to explain how it works and also why you should not use it. Knowledge is power, and even if I advice against using this technique it is also a good way to understand how SCOM uses display-strings in management packs. [/tab][tab name=”The Good News”] The Good NewsYes, you can use parameter replacement in you AlertName. With “parameter replacement” i mean using some kind of substitute text, or mnemonic if you like, that at run-time get translated into something useful. If you have written any kind of alert generating rules or monitors, you most like included something like $Data/Context/Property[@Name=’SomeDataFromAPropertyBag’]$ into your alert description. In this dialog, you also have the possibility to set the Alert Name. And if you are lazy, like I am, you probably also noticed that it is impossible to insert any kind of dynamic data into that field as well. This is especially annoying when you are writing a management pack that needs to look different in the Alert Views in the console, and you want to monitor 50 different Events or Performance counters or Log entries that are pretty much the same apart from a Name or ID.Of course I could not refrain from copy-pasting a $Data/Context…$ into the alert name only to realize that it simply is not being parsed and translated into the value of the specified parameter. Over time I have settled for a stand-point that it’s probably a performance issue and I have also used that as an argument for this apparent lack of simplicity that some of my customers have been questioning. Two, maybe three, years later. Microsoft releases an update to the core agent monitoring packs. Much to my surprise, one performance monitor suddenly generated alerts with a dynamic performance value in the Alert Name. You know, that field that is not gettingt parsed I was mentioning in the earlier paragraph. It actually looked pretty bad and made it very much impossible to practice any kind of alert supression, but still. It actually had a parsed value in the Alert Name.As the lack of this feature had me irked before, I exported the core MP and started reading through the XML to find out how they did it. To my surprise, it was actually pretty simple if you ditched the Authoring Console and used your trusty text-editor instead. [/tab][tab name=”How To Do It”] How To Do ItIn simple terms, if you know your SCOM XML out-side-in, you add the parameters to your “Alert” and modify your DisplayString, the one under LanguagePacks, to call that parameter by it’s relative ID. Just in case you happen to be a regular mortal, here’s the step-by-step guide. ;) In this example I have created a silly-simple Alert Generating EventLog rule in wich I have added some parameters to the description. It pretty much looks like this:Saving the MP at this point I will have a new WriteAlert action with a bunch of parameters and a displaystring with a unique ID.The resulting XML-code for the WriteAlert action looks like this: [xml highlight=”7,8,9,10,11,12,13”]&lt;WriteAction ID=&quot;Alert&quot; TypeID=&quot;Health!System.Health.GenerateAlert&quot;&gt; &lt;Priority&gt;1&lt;/Priority&gt; &lt;Severity&gt;2&lt;/Severity&gt; &lt;AlertName /&gt; &lt;AlertDescription /&gt; &lt;AlertOwner /&gt; &lt;AlertMessageId&gt;$MPElement[Name=&quot;TestMP.MyEventlogAlertRule.AlertMessage&quot;]$&lt;/AlertMessageId&gt; &lt;AlertParameters&gt; &lt;AlertParameter1&gt;$Data/EventDescription$&lt;/AlertParameter1&gt; &lt;AlertParameter2&gt;$Data/LoggingComputer$&lt;/AlertParameter2&gt; &lt;AlertParameter3&gt;$Data/UserName$&lt;/AlertParameter3&gt; &lt;AlertParameter4&gt;$Data/EventNumber$&lt;/AlertParameter4&gt; &lt;/AlertParameters&gt; &lt;Suppression /&gt; &lt;Custom1 /&gt; &lt;Custom2 /&gt; &lt;Custom3 /&gt; &lt;Custom4 /&gt; &lt;Custom5 /&gt; &lt;Custom6 /&gt; &lt;Custom7 /&gt; &lt;Custom8 /&gt; &lt;Custom9 /&gt; &lt;Custom10 /&gt;&lt;/WriteAction&gt;[/xml] In this slab of code, you’ve got the Parameters, their “relative ID” (the number in the Tag), and also the which is what you would need to search for among the displaystrings. Take note of the you want to use in your AlertName since you are going to need it later. A quick search for “TestMP.MyEventlogAlertRule.AlertMessage” will lead you to the actual message, which should looke similar to this: [xml]&lt;DisplayString ElementID=&quot;TestMP.MyEventlogAlertRule.AlertMessage&quot;&gt; &lt;Name&gt;I want Parameter Replacement here:&lt;/Name&gt; &lt;Description&gt;Event Description: {0}{1}{2}{3} &lt;/Description&gt;&lt;/DisplayString&gt;[/xml] You should have one of these for every language you have configured in your management pack.As you may notice, the Description does not contain any XPaths of any kind but rather references to the parameters defined in the WriteAction. That would be the {X} thingies within the description tags. You may also notice that the AlertParameters starts from “1” while the parameter references begin with “0”. In practice, that means that {0} in the displaystring definition equals to AlertParameter1 and so forth. Now, with this in mind, adding a Parameter to AlertName if very simple and straight-forward. Simply decide which parameter your want to use and add it’s reference to the Name definition.So, let’s say I have the above alert message and I want to include UserName in the Alert Name, I would change the &lt;Name&gt; tag to: [xml]&lt;Name&gt;I want Parameter Replacement here:{2}&lt;/Name&gt;[/xml] That’s it folks!Save the XML, make sure you verify it and import it into your Operations Manager LAB and watch the magic. Just make sure you continue reading this post as the next part about the downsides is pretty important. [/tab][tab name=”What’s the Downside?”] What’s the Downside?The negative effects of using Parameter Replacement in AlertName really boils down to two main perspectives. These are, if I may say to, pretty major and is the reason I have been reluctant on posting this, sort of, how-to. You are breaking your subscriptions and connectors!Apparently, parameter replacement is not working in subscriptions and connectors, be it 3:rd-party, Universal, Orchestrator IPs et.c. Basically anything other than the Operations Console will not be able to handle your parameters in AlertName. This will give you a “{1} in {2} has received an error” instead of “veryimportant.log in C:\\Logs\\ImportantSystem\\ has received an error” in anything except the Operations Console. Now, this might not be a bad thing if the Operations Console is your only interface to Operations Manager, but if you would like to forward these alerts to a mobile phone, IM user or a mail recipient it will be utterly useless. I have not verified this, but I am not sure if Alert Suppression is actually parsing the parameters as well. Also. If you, by means of connectors or System Center Orchestrator, are generating incidents from alerts the AlertName forwarded will be equally useless for anyone receiving it. It’s killing your health perspective.Might sound drastic, but I’m quite serious about this. Using Parameter Replacement in AlertName might be useful for alert generating rules, but should never be used in a monitor. The reason is pretty simple actually. If you are using a monitor, you are without a doubt interested in it’s state. Otherwise, you would not use a monitor, am I right? I cannot see how it would make sense to create a monitor that does not reflect the health of a specific checkpoint. Much less having a monitor generating alerts that might confuse any service desk operator about what monitor that caused the alert. Also–I have not tested this–I assume that a monitor would not update it’s AlertName once the alert are generated making it more difficult to troubleshoot. Alert generating rules are, to me, something I tend to use only when all other options fail for some reason and I do not like to monitor things to cannot have health. And since parameters in AlertName is nothing for monitors I also question whether it actually is usable at all.[/tab][tab name=”Conclusion”] The ConclusionWhile this is an interesting techique and a good way to enjoy MP Authoring and learn about the behaviour of display strings and languages in you Management Packs, I would definitely consider it a mostly academical exercise. Only in extreme use-cases and situations would I consider it a viably option and while it might look good in the console, do be aware of the limitations. I have also not seen anything about it on MSDN, and I have serious doubts about it being a supported feature. I have personally been using it in transition to a “better” management pack to get alerting running quickly, yet a prefered solution would actually be using a custom datasouce and a decent macro-enabled text-editor–not to mention snippets–to bulk-generate your monitors and/or rules. MP Authoring is fun and powerful – be resposible[/tab][end_tabset]","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"MP Development","slug":"MP-Development","permalink":"http://stegenfeldt.github.io/tag/MP-Development/"}]},{"title":"Virtual OpenVPN Server at Home","slug":"virtual-openvpn-server-at-home","date":"2011-09-28T06:37:39.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"Linux/virtual-openvpn-server-at-home/","link":"","permalink":"http://stegenfeldt.github.io/Linux/virtual-openvpn-server-at-home/","excerpt":"","keywords":null,"text":"I was going to write a post on how to install and configure your own virtual SSL-VPN server as I had in mind to make one myself as a means to surf safely while on hotspots and to access my System Center lab at home. I’m not gonna do that. Instead I just want to point to this free, already pre-configured, OpenVPN Virtual Appliance. Just follow its instructions and it will work quite nicely. Have fun.","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/topics/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/tag/Linux/"},{"name":"OpenVPN","slug":"OpenVPN","permalink":"http://stegenfeldt.github.io/tag/OpenVPN/"},{"name":"Virtual Appliance","slug":"Virtual-Appliance","permalink":"http://stegenfeldt.github.io/tag/Virtual-Appliance/"}]},{"title":"OpsMgr 2007 R2 Documentation","slug":"opsmgr-2007-r2-documentation","date":"2011-08-08T20:52:27.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"opsmgr2007/opsmgr-2007-r2-documentation/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/opsmgr-2007-r2-documentation/","excerpt":"","keywords":null,"text":"Here a link to the System Center Operations Manager 2007 R2 Documentation for those of you out there who keeps asking of its whereabouts and then tell me to not tell you to google for it. So now I can direct you to my site, tell you to click on “OpsMgr 2007” to the left and browse through my posts instead of wasting precious time on googling and pretend being more helpful.To the rest of the world, sorry for wasting your time! Happy now, eh?","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"Rant","slug":"Rant","permalink":"http://stegenfeldt.github.io/tag/Rant/"},{"name":"Sillyness","slug":"Sillyness","permalink":"http://stegenfeldt.github.io/tag/Sillyness/"},{"name":"Teach a Man to Fish","slug":"Teach-a-Man-to-Fish","permalink":"http://stegenfeldt.github.io/tag/Teach-a-Man-to-Fish/"}]},{"title":"Bulk disable ACS Forwarders (with wildcards)","slug":"bulk-disable-acs-forwarders-with-wildcards","date":"2011-07-07T08:59:24.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"opsmgr2007/PoSH/bulk-disable-acs-forwarders-with-wildcards/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/PoSH/bulk-disable-acs-forwarders-with-wildcards/","excerpt":"Here’s a little something-something for the wicked. Me and my apprentice is currently decommissioning an entire Management Group with a thousand (-ish) agents. Long story short, we got a new Management Group, migrated all the agents, added a couple of hundreds more, deployed a bunch of gateways and now we are shutting down the old one. Now, uninstalling the old Management Group from all the agents is a breeze using SCCM and handling the few 20-ish servers that are left is not a biggie either. Shutting down ACS, however, is a different matter.","keywords":null,"text":"Here’s a little something-something for the wicked. Me and my apprentice is currently decommissioning an entire Management Group with a thousand (-ish) agents. Long story short, we got a new Management Group, migrated all the agents, added a couple of hundreds more, deployed a bunch of gateways and now we are shutting down the old one. Now, uninstalling the old Management Group from all the agents is a breeze using SCCM and handling the few 20-ish servers that are left is not a biggie either. Shutting down ACS, however, is a different matter. Although you do configure your forwarders using Operations Manager, removing the management group you were running ACS in does not mean the agents will shut down and disable the AdtAgent service or stop trying to forward audit events to your collector. Now, selecting 10 agents at the time and running the “Disable Audit Collection” task–in case you did not know, there’s a limitation on how many agents you can run a task on in the Operations Console–is not my idea of a jolly good day and since Powershell is a bucket of joy in comparison; here’s a script for you all! DisableACSForwarders It is zipped to avoid security alerts, but as with any script found on the internet I implore to to read the code before actually running it. Anyway, you can use it in a couple of ways. To run it interactively, just go to the directory where you unpacked it and run it. You will be requested to enter the FQDN of you Root Management Server and a wildcard search for ACS Forwarders.For example: [plain]PS C:..\\Scripts&gt; .\\DisableACSForwarders.ps1Root Management Server: rms.teknoglot.localACS Forwarder name (wildcard): *.teknoglot.local[/plain] You can also run it with parameters (for scheduling?) like this: [plain]PS C:..\\Scripts&gt; .\\DisableACSForwarders.ps1 rms.teknoglot.local *.teknoglot.local[/plain] If you need to run the task with different credentials there’s a switch for that. Just add -UseCredentials to the command and you will be prompted for it.Like this: [plain]PS C:..\\Scripts&gt; .\\DisableACSForwarders.ps1 -UseCredentials[/plain] As you might already have realized, the wildcard search does not require actual wildcards. If you only want to disable the ACS forwarder on a single machine, just enter it’s FQDN. As for what wildcards it will accept; anything supported by the powershell -like operator is valid. [UPDATE!] You might get false failures when running the script on clustered machines because of a bug in the AC Management Pack For the source code, read on! [ps] Using parameters for RMS and wildcard searchparam( [string]$rootManagementServer = $(Read-Host -Prompt &quot;Root Management Server&quot;), [string]$filterAgents = $(Read-Host -Prompt &quot;ACS Forwarder name (wildcard)&quot;), [switch]$UseCredentials) Make sure the $rootManagementServer variable is definedwhile (-not $rootManagementServer) { Write-Host &quot;`nRoot Management Server MUST be defined!&quot; -ForegroundColor Red [string]$rootManagementServer = $(Read-Host -Prompt &quot;Root Management Server&quot;)} if ($UseCredentials -eq $true) { $taskCredentials = Get-Credential} $startLocation = Get-Location$checkPSSnapin = Get-PSSnapin | where {$_.Name -eq &quot;Microsoft.EnterpriseManagement.OperationsManager.Client&quot;}if ($checkPSSnapin -eq $null) { Add-PSSnapin &quot;Microsoft.EnterpriseManagement.OperationsManager.Client&quot;}$result = Set-Location &quot;OperationsManagerMonitoring::&quot;$result = New-ManagementGroupConnection -ConnectionString:$rootManagementServer$result = Set-Location $rootManagementServer $acsForwarderClass = Get-MonitoringClass -Name &quot;Microsoft.SystemCenter.ACS.Forwarder&quot;$agentNames = Get-MonitoringObject -monitoringclass:$acsForwarderClass | where {$_.Path -like $filterAgents} | Select Path$successfulTasks = @()$skippedTasks = @()$failedTasks = @() $monitoringClass = Get-MonitoringClass -Name &quot;Microsoft.SystemCenter.Agent&quot;if ($agentNames -ne $null) { Write-Host &quot;nFound&amp;quot;$agentNames.Count&amp;quot;ACS forwarders with wildcard $filterAgents&amp;quot; Write-Host &amp;quot;nnWaiting for 5 seconds to give you a chance to abort!n&quot; Start-Sleep -Seconds 5 Write-Host &quot;Time’s UP!nn&quot; $agentNames | ForEach-Object { $agentName = $.Path Write-Host &quot;Disabling Audit Collection on&quot; $agentName $monitoringObject = Get-MonitoringObject -monitoringclass:$monitoringClass | where {$.DisplayName -like $agentName} $agentTask = $monitoringObject | Get-Task | where {$_.Name -eq &quot;Microsoft.SystemCenter.DisableAuditCollectionService&quot;} if ($monitoringObject.IsAvailable -eq $true) { if ($credentials -eq $null) { $result = Start-Task -Task $agentTask -TargetMonitoringObject $monitoringObject } else { $result = Start-Task -Task $agentTask -TargetMonitoringObject $monitoringObject -Credential $taskCredentials } if ($result.Status -eq &quot;Succeeded&quot;) { Write-Host &quot;Operation Successful!&quot; -ForegroundColor Green Write-Host n $successfulTasks += $agentName } else { Write-Host &amp;quot;Operation failed.&amp;quot; -ForegroundColor Red Write-Host $result.ErrorMessage Write-Hostn $failedTasks += $agentName } } else { Write-Host &quot;The agent is unavailable, Skipping!&quot; Write-Host n $skippedTasks += $agentName } } Write-Host &amp;quot;Summary&amp;quot; Write-Host &amp;quot;tSuccessful:t&amp;quot;$successfulTasks.count Write-Host &amp;quot;tFailed:tt&quot;$failedTasks.count Write-Host &quot;tSkipped:t&quot;$skippedTasks.count} else { Write-Host &quot;`nNo ACS Forwarders found using wildcard $filterAgents&quot;} Set-Location $startLocation[/ps] Enjoy!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"PoSH","slug":"opsmgr2007/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/PoSH/"}],"tags":[{"name":"ACS","slug":"ACS","permalink":"http://stegenfeldt.github.io/tag/ACS/"},{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"}]},{"title":"OpsMgr 2007 Connectivity Map","slug":"opsmgr-2007-connectivity-map","date":"2011-05-17T09:47:18.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"opsmgr2007/opsmgr-2007-connectivity-map/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/opsmgr-2007-connectivity-map/","excerpt":"","keywords":null,"text":"I’ve had this little visio drawing lying around on my desktop for a while now and I thought that it might be a nice thing to share. It is nothing ground breaking at all and all the information is available at the Operations Manager 2007 R2 Supported Configurations page on Technet, but I find the visual map easier to read and I use it personally to quickly look up all port openings for the most common components in Operations Manager. It is missing a few components like ACS, AEM and XPlat, but I usually just look them up when needed. Have fun!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Quick Reference","slug":"Quick-Reference","permalink":"http://stegenfeldt.github.io/tag/Quick-Reference/"}]},{"title":"Introduction to TG WinAutoSvc v1","slug":"introduction-to-tg-winautosvc-v1","date":"2011-04-29T09:35:47.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"opsmgr2007/introduction-to-tg-winautosvc-v1/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/introduction-to-tg-winautosvc-v1/","excerpt":"","keywords":null,"text":"BackgroundFor quite some time now I’ve had this idea spinning around in my head to write a couple of blog-posts about some of the more useful techniques available when building management packs. Many of these techniques are already described on MSDN and Technet- or other blogs as well as on various forums, but often no more than small bits and pieces of them and I have yet to see some humanly readable information about how to tie them together into a useful management pack. I say “humanly readable” because the information you do find online so far may be clear and somewhat easy to understand for someone with a system development background and a pretty good idea of how object oriented development models tend to work. But the real life System Center Operations Manager engineer–you know the one who get those “do you think we could monitor our …-system too?” questions a couple of times a week, you know… you (most likely, being here)–tend to have a completely different background. Yet as their OpsMgr environment grows, so does the demand for custom monitoring and all of a sudden the former server engineer are now also a developer. A developer who has never before had the need to grasp such abstract concepts as classes, instances, inheritance and who probably never before have had any reason whatsoever to write any XML code. PurposeMy idea for this series of posts is to shed some light into the world of the authoring console and modules and cookdown and so forth. I am by no means an accredited author, but I will do my best to stay human in this venture and in plain english try to explain why and how you do certain things when going from Management Pack templates, rules, monitors and the safe haven that is authoring in the Operations Console into making your scripts resuable, easy to extend and prime for cookdown using the Authoring Console and XML. The TG WinAutoSvc Management PackTo give the series some kind of context and at the same time not only be a matter of examples I will base them on a fully functional management pack that discovers and monitors all Windows services that are set to automatic startup. I know there is other similar management packs out there but I haven’t fancied any one of them yet, and since I had the idea of writing this series I decided that building a new one would be a good way to go. Some of the interesting features with this management pack is: You will get an instance of the service classes for each and every service. It uses different classes for Own Process services and Shared Process services (svchost for example). Every service have a health state (you can use them in distributed applications). The service state monitors are inherited from their base classes, no coding neccesary. There is only one discovery script for all kinds of windows services. Extending the discovery to include different kinds of windows services, like kernel processes, is a matter of filtering. It is Open Source and licensed under the Eclipse Public License v1.Most of these features will be described thoroughly in later posts in the series and as development of it progresses I will document what I do, how I do it and why I do it in certain ways. Hopefully you will learn something new through this and get closer to becoming that MP Dev the organization asks for.In the mean time, feel free to download, look at the source code (which it by no means perfect) and try it out. The TG WinAutoSvc monitoring management pack is available for download here:http://code.google.com/p/tg-winautosvc/downloads/detail?name=TG.WinAutoSvc.xml The latest revision of the source code is located here:http://code.google.com/p/tg-winautosvc/source/browse/trunk/TG.WinAutoSvc.xml A small word of advice though. If you implement this in your environment, remember that you probably have alot more automatic services than you would expect. Because of this, discovery is disabled by default. Best of luck, and enjoy!","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"MP Development","slug":"MP-Development","permalink":"http://stegenfeldt.github.io/tag/MP-Development/"}]},{"title":"Server problems fixed! (hopefully)","slug":"server-problems-fixed-hopefully","date":"2011-04-27T19:50:12.000Z","updated":"2016-05-19T09:11:09.329Z","comments":true,"path":"tb/server-problems-fixed-hopefully/","link":"","permalink":"http://stegenfeldt.github.io/tb/server-problems-fixed-hopefully/","excerpt":"","keywords":null,"text":"I think I got the server running ok now. I’ve been fiddling about quite alot and unfortunately don’t know which one action that fixed the problem. If I do figure it out, I will post it here. Site performance should be a bit better now.","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[]},{"title":"Sluggish performance on teknoglot","slug":"sluggish-performance-on-teknoglot","date":"2011-04-19T20:14:02.000Z","updated":"2016-05-19T09:11:09.328Z","comments":true,"path":"tb/sluggish-performance-on-teknoglot/","link":"","permalink":"http://stegenfeldt.github.io/tb/sluggish-performance-on-teknoglot/","excerpt":"","keywords":null,"text":"I, as well as others, have noticed some slow performance from my blog lately and I just wanted to let you know that the root cause have been identified as a bug in on of the crypto libs on the server. I haven’t found a working solution yet but are trying to keep an eye on the site regularly to be able to bounce the problematic services when they start to act up. Hopefully there will be a fix available soon. Sorry for any inconvenience in the meantime.","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[{"name":"Teknoglot","slug":"Teknoglot","permalink":"http://stegenfeldt.github.io/tag/Teknoglot/"}]},{"title":"Move complete, welcome to teknoglot.se!","slug":"move-complete-welcome-to-teknoglot-se","date":"2011-02-04T13:07:41.000Z","updated":"2016-05-19T09:11:09.328Z","comments":true,"path":"tb/move-complete-welcome-to-teknoglot-se/","link":"","permalink":"http://stegenfeldt.github.io/tb/move-complete-welcome-to-teknoglot-se/","excerpt":"","keywords":null,"text":"Oh my God, I actually moved my blog for real. I think I’ve been putting this upp for nearly half a year now and even though I actually went and bought a “real” domain-name for it. But now it’d done. The server is now self-hosted and self-maintained. Now, that obviously gives me a bit more to do, but on the other hand. I can fix any problems myself and not have to create tickets and hope someone responding to them knows what they’re talking about. The design is mostly borrowed, for now, but it works and I hope I did all the HTACCESS rules on the old server correct so that they forward all the old links to the same post on the new one. So, welcome!","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[]},{"title":"I'm moving (finally)","slug":"im-moving-finally","date":"2011-02-01T11:10:52.000Z","updated":"2016-05-19T09:11:09.328Z","comments":true,"path":"tb/im-moving-finally/","link":"","permalink":"http://stegenfeldt.github.io/tb/im-moving-finally/","excerpt":"If you’re seeing this, the move went OK. :P Anyway, I have tried to make sure that all the links, images and urls are still intact and that people are automatically redirected to the correct address on the new site too. I think I got it right, but who knows? Still fiddling with the themes thought. Sorry for the inconvenience! ps. Post from the old site is a jump ahead.","keywords":null,"text":"If you’re seeing this, the move went OK. :P Anyway, I have tried to make sure that all the links, images and urls are still intact and that people are automatically redirected to the correct address on the new site too. I think I got it right, but who knows? Still fiddling with the themes thought. Sorry for the inconvenience! ps. Post from the old site is a jump ahead. Hi all, I’m finally getting my male donkey out of the wagon and has started moving this blog to a new self-hosted server. The current host is cheap and delivers quite the good service, but since I already have servers running 24/7 at home, with attached electric bills, and more than enough bandwidth for a couple of websites I find it silly paying for yet-another hosting solution. Also, it is a good time to do some spring-cleaning and actually start using that teknoglot.se domain i bought some time ago. :P Hopefully, the transition will go mostly unnoticed apart from the automatic redirect (301 - Permanently moved) to the new domain.","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[]},{"title":"SNMP GET Errors in OpsMgr EventLog","slug":"snmp-get-errors-in-eventlog","date":"2010-09-02T20:28:07.000Z","updated":"2016-05-19T09:37:38.361Z","comments":true,"path":"opsmgr2007/snmp-get-errors-in-eventlog/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/snmp-get-errors-in-eventlog/","excerpt":"","keywords":null,"text":"I’ve been building a little SNMP Management Pack in the past few days to discover and monitor a bunch of PowerWare UPS’s, which turned out to take quite a lot more energy and time than expected. Mostly due to the facts that I am really bad with SNMP and how it works, I’ve never really looked into the inner working of building an SNMP management pack and also because we ran into a couple of errors preventing the discovery process to work alright. To make it clear right away, this is not going to be a “Building an SNMP Management Pack Tutorial” since there’s plentiful good ones out there already, and to be extra helpful I’m gonna include a few links right away: SNMP Setup and Simple Custom SNMP Discovery - Pretty much the basics SNMP Management Pack Example: NetApp Management Pack - Part 4 actually, but has the links to the other parts Creating SNMP Probe Based Monitors - No custom discovery, but a good and simple guide to SNMP ProbesIt’s the second, the NetApp one, I’ve used as a guide to building the UPS management pack since it goes through the process of building your own filtered discovery using SystemOID to identify your hardware-classes and then building the monitors on top of those. Let’s get to itWhen building the discovery of my hardware classes I ran into problems. The discovery simply did not work. At first I got some strange errors about “invalid queries”, something that turned out to be related to me reading two guides–seriously though, pick one guide that is closest to what you want to achieve and stick to it–and mixing up the XPathQuery variables. Silly me.I got those errors to go away and I was able to get a few objects to my base-class, but none of the hardware classes who was populated through the return value of an SNMP OID got discovered.The only error I got this time was the following: ´´´Log Name: Operations ManagerSource: Health Service ModulesDate: 2010-09-02 11:19:12Event ID: 11001Task Category: NoneLevel: ErrorKeywords: ClassicUser: N/AComputer: CENSOREDDescription:Error sending an SNMP GET message to IP Address XX.XX.XX.XX, Community String:=CENSORED, Status 0x6c. One or more workflows were affected by this. Workflow name: CENSORED.MP.CLASS.DISCOVERYInstance name: CENSORED_DEVICENAMEInstance ID: {5C7EFB30-D885-8843-0DD7-EA86B4FD2311}Management group: CENSORED´´´ I went through all the other logical steps of troubleshooting an error like that which include double-checking firewall settings, OIDs, IP-addresses, allowed hosts and so forth. It wasn’t until I loaded the PowerMIB into a MIB Browser installed on the proxy machine (in this case a Management Server) I realized that there was no problem sending an SNMP GET to the UPS from that server. I launched Wireshark and had it listen to SNMP traffic between the UPS and the Management Server. The thing that struck me right-away was the fact that I could see the a bunch of “SNMP Get-Request” but no “SNMP Get-Response” which means that Operations Manager did send an SNMP GET but there was no response.After a bit of intense staring i noticed what you see in the screenshot.For some reason Operations Manager does not care about what SNMP version you configure when you do the initial discovery of a network device. Even if you do specify SNMP v1, you probes may very well be using SNMP v2c instead and in many cases that will result in these SNMP GET errors in the Operations Manager event log.To avoid this, you haves to specify which SNMP version to use in your System.SnmpProbe according to the information provided here: http://msdn.microsoft.com/en-us/library/ee809331.aspxSince I am such a nice guy, here’s an example of the working probe with the added line highlighted.[xml highlight=”4”]&lt;IsWriteAction&gt;false&lt;/IsWriteAction&gt;&lt;IP&gt;$Config/IP$&lt;/IP&gt;&lt;CommunityString&gt;$Config/CommunityString$&lt;/CommunityString&gt;&lt;Version&gt;1&lt;/Version&gt;&lt;SnmpVarBinds&gt; &lt;SnmpVarBind&gt; &lt;OID&gt;1.3.6.1.4.1.534.1.1.1.0&lt;/OID&gt; &lt;Syntax&gt;0&lt;/Syntax&gt; &lt;Value VariantType=&quot;8&quot;&gt;&lt;/Value&gt; &lt;/SnmpVarBind&gt; &lt;SnmpVarBind&gt; &lt;OID&gt;1.3.6.1.4.1.534.1.1.2.0&lt;/OID&gt; &lt;Syntax&gt;0&lt;/Syntax&gt; &lt;Value VariantType=&quot;8&quot;&gt;&lt;/Value&gt; &lt;/SnmpVarBind&gt; &lt;SnmpVarBind&gt; &lt;OID&gt;1.3.6.1.4.1.534.1.1.3.0&lt;/OID&gt; &lt;Syntax&gt;0&lt;/Syntax&gt; &lt;Value VariantType=&quot;8&quot;&gt;&lt;/Value&gt; &lt;/SnmpVarBind&gt;&lt;/SnmpVarBinds&gt;[/xml]That’s it. Working perfectly now.Best of luck to you too.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"TroubleShooting","slug":"TroubleShooting","permalink":"http://stegenfeldt.github.io/tag/TroubleShooting/"}]},{"title":"Installing Linux Integration Services v2.1 on Red Hat ES 5","slug":"install-linuxis21-rhes5","date":"2010-08-31T10:06:04.000Z","updated":"2016-05-19T09:11:09.328Z","comments":true,"path":"hyperv/rhes/install-linuxis21-rhes5/","link":"","permalink":"http://stegenfeldt.github.io/hyperv/rhes/install-linuxis21-rhes5/","excerpt":"","keywords":null,"text":"Ok, so I got the task to install the Linux Integration Service for Hyper-V R2 on a RedHat Enterprise Server 5. Something that turned out to be a bit more to handle than I would have thought. So here’s a little How-To. PreparationsRead the documentation provided in the Linux Integration Services download. Much of the information in this article is in there, but some parts are not. Otherwise I would not have bothered writing about it. ;) I’m not going to go through the OS installation process here, but make sure to select the “Software Development” packages since you will be needing it. In case you missed it, you can install them later by running these commands. [plain]# yum groupinstall &quot;Development Tools&quot; yum install kernel-headers[/plain]I’m not actually sure that you need to run the kernel-headers install manually or if it’s included in the “Development Tools” package. The first gotcha i ran into was the fact that the link to the Linux Integration Services–previously known as Linux Integration Components or LinuxIC–on RedHat’s information pages gave me a 404 and a redirect to a bing-search that returned the exact same 404. The page have simply been removed by Microsoft without any form of redirection to the new page. Anyway, a search on http://download.microsoft.com for “Linux Integration Components” do return the new page, and that’s where I learned about the new name._Thank you for making it easy for us Microsoft!_Here’s a direct link to the search on the current name: http://www.microsoft.com/downloads/en/results.aspx?freetext=linux+integration+services&amp;displaylang=en&amp;stype=s_basicAnd here’s a direct link to the actual download page: http://www.microsoft.com/downloads/details.aspx?displaylang=en&amp;FamilyID=eee39325-898b-4522-9b4c-f4b5b9b64551 This download contains an ISO file that you can mount using the Hyper-V- or VMM-console, or you can do as I did and download the ISO to the virtual machine, mount it locally, copy the files and unmount it. Like this. [plain] mkdir /mnt/ISOmount -o loop /root/LinuxIC v21.iso /mnt/ISOmkdir /opt/linux_ic_v21_rtmcp /mnt/ISO/* -R /opt/linux_ic_v21_rtm/umount /mnt/ISO[/plain] You probably have to be root to do this by the way.With that done, let’s get to the installation. InstallationAs root, do the following: [plain] export PATH=$PATH:/sbincd /opt/linux_ic_v21_rtm/makemake installreboot[/plain] Why the export PATH command? Apparently, on RHES5, /sbin is not in the PATH by default and this is something that the make scripts are completely unaware of. The “make install” will try to run “depmod” which will fail since it’s not in the default path. You could also add “PATH=$PATH/sbin” to the root users ~/.bashrc which will put it back in the PATH but only for the root user, but I don’t know if that’s recommended.And, yes. You DO have to reboot after the install. If you are running RHES5 64bit you also have to install the “adjtimex” package. It is in the RHN repository but also on the RHES5 Installation CD in case you have no internet connection. Install it with yum like this: [plain]# yum install adjtimex[/plain] And from the CD (mount it first) like this: [plain]# rpm –ivh /mnt/cdrom/Server/adjtimex-1.20-2.1.x86_64.rpm[/plain] And that’s basically it for the installation. VerificationHow do you know that the driver are installed? After the reboot, try running “modinfo vmbus” which should return something like this: [plain]# modinfo vmbusfilename: /lib/modules/2.6.18-194.11.1.el5/kernel/drivers/vmbus/vmbus.koversion: 2.1.25license: GPLsrcversion: 3C1899C419665CB2514F2D0depends:vermagic: 2.6.18-194.11.1.el5 SMP mod_unload gcc-4.1parm: vmbus_irq:intparm: vmbus_loglevel:int[/plain] Try that with netvsc, storvsc and blkvsc too (replace the vmbus part) and you should get something similar. If you don’t, the installation did not succeed.The documentation also tells us to check that the components are running with “/sbin/lsmod | grep vsc” which should return: [plain]# /sbin/lsmod | grep vscblkvsc 70184 3storvsc 64264 0netvsc 73504 0vmbus 88304 3 blkvsc,storvsc,netvscscsi_mod 196953 6 scsi_dh,sg,blkvsc,storvsc,libata,sd_mod[/plain] The numbers will probably differ from installation to installation depending on blocksizes and allocation. ConfigurationConfiguration is pretty straight-forward so I’ll keep this short. When you install the drivers you will get a new network card called seth0, which I presume stands for Synthetic ETHernet. There’s nothing magic about it regarding configuration and “system-configuration-network” will work just fine. The drivers will also give you a couple of SCSI-devices (if you have one attached) with the regular /dev/sd* naming. Simply configure these using fdisk or whatever GUI you might prefer. There is also a note in the documentation about changing the grub configuration in the “Additional Information…” section. Do read that section. Additional CommentsOne thing I tend to do now that disk space is dirt cheap is to copy all ISO-files I use locally instead of mounting them when needed through Hyper-V. Simply because you can bet your insert-shorter-word-for-buttocks that the day you need it again, someone has been kind enough to have done som spring-cleaning or it’s locked by another machine in the cluster. If you have it locally and followed my instructions in the “Preparation” section, you will allready have a /mnt/ISO directory. Only thing you’ll have to do is [plain] mount -o loop /path/to/your.iso /mnt/ISO[/plain] And there you have it. Just remember to unmount it when you’re done. I also almost never use the Hyper-V remote connection interface thingy since it will give you a GUI and the mouse just won’t work. If you haven’t configured a network card yet though, you could connect through Hyper-V and hit Ctrl+Alt+F1 to get a command prompt. Unfortunatly cut/paste don’t work here, but you could run system-configuration-network, assign an IP-address and then connect with an SSH client. I prefer PuTTY to a degree that I usually install the ported version on my Linux desktops aswell. And I never logon using root. People should know this, but it should be stressed anyway. Always logon as regular user and su or sudo when needed. I can’t understand why RHES has root-login enabled by default in the SSH-server config. Good luck!","raw":null,"content":null,"categories":[{"name":"Hyper-V","slug":"hyperv","permalink":"http://stegenfeldt.github.io/topics/hyperv/"},{"name":"RedHat ES","slug":"hyperv/rhes","permalink":"http://stegenfeldt.github.io/topics/hyperv/rhes/"}],"tags":[{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"Hyper-V","slug":"Hyper-V","permalink":"http://stegenfeldt.github.io/tag/Hyper-V/"},{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/tag/Linux/"},{"name":"RedHat","slug":"RedHat","permalink":"http://stegenfeldt.github.io/tag/RedHat/"},{"name":"RHES5","slug":"RHES5","permalink":"http://stegenfeldt.github.io/tag/RHES5/"}]},{"title":"MSMQ 4 and MSMQ 5 MP for OpsMgr Released! (finally)","slug":"msmq-4-and-msmq-5-mp-for-opsmgr-released-finally","date":"2010-04-06T10:09:57.000Z","updated":"2016-05-19T09:11:09.328Z","comments":true,"path":"opsmgr2007/msmq-4-and-msmq-5-mp-for-opsmgr-released-finally/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/msmq-4-and-msmq-5-mp-for-opsmgr-released-finally/","excerpt":"","keywords":null,"text":"After a long wait (definitely more than 90 days) the management packs for MSMQ 4 (Windows 2008) and MSMQ 5 (Windows 2008 R2) are finally released. Both seem to be fully Cluster aware and pretty much holds the same monitoring as the the latest MSMQ 3 MP. Message Queuing 4.0 Management Pack for Operations Manager 2007&gt; **Quick Details** Version: 6.0.6700.83 Date Published: 4/5/2010 Language: English Download here: http://www.microsoft.com/downloads/details.aspx?FamilyID=cfc103b8-7185-4721-8098-110885fe9e9e&amp;displaylang=en Message Queuing 5.0 Management Pack for Operations Manager 2007 Quick Details Version: 6.0.6700.88 Date Published: 4/5/2010 Language: English Download here: http://www.microsoft.com/downloads/details.aspx?FamilyID=28349b78-8329-44aa-8a1f-81f4e3f84d0c&amp;displaylang=en","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"MSMQ","slug":"MSMQ","permalink":"http://stegenfeldt.github.io/tag/MSMQ/"}]},{"title":"Change Gateway Powershell Script","slug":"change-gateway-powershell-script","date":"2010-03-31T13:27:08.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/PoSH/change-gateway-powershell-script/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/PoSH/change-gateway-powershell-script/","excerpt":"","keywords":null,"text":"This script has pretty much already been covered in my previous post about Changing or Replacing an Operations Manager Gateway Server. This time I’ve basically put parameter support in it to make it easier to use. Here’s the script anyway. [ps] Param($OldGW,$NewGW) $OldMS= Get-ManagementServer | where {$.Name -eq $OldGW}$NewMS = Get-ManagementServer | where {$.Name -eq $NewGW}$agents = Get-Agent | where {$_.PrimaryManagementServerName -eq $OldGW}$agents = $agents&amp;amp;quot;Moving &amp;amp;quot; + $agents.count + &amp;amp;quot; agents from &amp;amp;quot; + $OldMS.Name + &amp;amp;quot; to &amp;amp;quot; + $NewMS.NameStart-Sleep -m 200Set-ManagementServer -AgentManagedComputer: $agents -PrimaryManagementServer: $NewMS -FailoverServer: $OldMS [/ps] To use it, create a textfile called ChangeGW.ps1 and paste the code into it. Save the file somewhere neat (maybe C:Scripts) for easy access. If you don’t feel like copy/pasting, you can download the script here. To use it, open the Operations Manager Command Shell and type:C:ScriptsChangeGW.ps1 &lt;old.gatewayserver.dns.name&gt; &lt;new.gatewayserver.dns.name&gt; For example: [plain]C:ScriptsChangeGW.ps1 gwserver01.domainname.local gwserver02.domainname.local[/plain]","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"PoSH","slug":"opsmgr2007/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/PoSH/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"}]},{"title":"ESENT Error When Modifying OpsMgr Agent","slug":"esent-error-when-modifying-opsmgr-agent","date":"2010-03-19T09:34:17.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/esent-error-when-modifying-opsmgr-agent/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/esent-error-when-modifying-opsmgr-agent/","excerpt":"","keywords":null,"text":"Getting “ESENT Kerys are required to install this application” when you are trying to modify/change an agent installation? This seems to be most common on Windows 2008 and i guess it’s because of the UAC and the fact that opening the Control Panel isn’t running in administrative mode. To work around this you need to run the msiexec command on the correct installation GUID from an administrative command prompt. Besides running through the registry to find the GUID, one of the easier ways is this: Open an administrative command prompt. run wmic product Locate your product by its name, the GUID (looks a bit like this {25097770-2B1F-49F6-AB9D-1C708B96262A}) directly after that is the one you want. Copy it. run msiexec /i &lt;PASTEYOURGUIDHERE&gt; Modify the agent as pleasedThat’s pretty much it. Good luck.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"Windows","slug":"Windows","permalink":"http://stegenfeldt.github.io/tag/Windows/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"Windows Installer","slug":"Windows-Installer","permalink":"http://stegenfeldt.github.io/tag/Windows-Installer/"},{"name":"WMI","slug":"WMI","permalink":"http://stegenfeldt.github.io/tag/WMI/"}]},{"title":"Updated MSMQ Management Pack v6.0.6615.0!","slug":"updated-msmq-management-pack","date":"2009-12-23T08:57:38.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/updated-msmq-management-pack/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/updated-msmq-management-pack/","excerpt":"","keywords":null,"text":"Microsoft has released an update to the MSMQ (version 3) management pack. System Center Pack for: Message Queuing 3.0Version: 6.0.6615.0Released on: 12/14/2009 Message Queuing (also known as MSMQ) is a server application that enables applications to communicate across heterogeneous networks and systems that may be temporarily offline or otherwise inaccessible. Instead of an application communicating with a service on another computer, it sends its information to Message Queuing, which sends the information to a Message Queuing service on the target computer where it is made available to the other application. Message Queuing provides guaranteed delivery, efficient routing, security, and priority based messaging. Now, what’s really interesting is what you will find in the MP Guide under “Supported Configurations”. The Message Queuing Management Pack for Operations Manager 2007 is designed to monitor Message Queuing version 3 only. The Message Queuing Management Pack supports the following platforms: · Windows Server 2003 · Windows XP The Message Queuing Management Pack also supports monitoring clustered MSMQ components. Text coloration is obviously added by me to highlight the interesting part. ;) Finally MSMQ monitoring seems to be cluster aware, which might mean that the home-made pack i did to have those (numerous) queues covered could be passed on to the scrap-heap. This is also confirmed under “Changes in This Update”. The December 2009 update to this management pack includes the following change: · Fixed a problem when working with an instance of MSMQ in a Cluster. The MP is now able to discover and monitor public and private queues in a cluster. · Fixed a problem when discovering the local and cluster instance of MSMQ. The MP is now able to discover and monitor both instances. The confusing double RunAs profiles seems to have been cleaned up too (you only have to worry about one now) as well as fixing some sloppy mistakes in the previous scripts (no Option Explicit? C’mon Microsoft! You write the best practices, try to stick to them.) and generally improving display and documentation. Gonna import this to our staging environment today and let it roll during the holidays. Cheers! Oh, and happy holidays! Download and documentation:http://www.microsoft.com/downloads/details.aspx?FamilyId=1D2B4398-8BC2-4A43-850C-852EBB0D983B&amp;displaylang=en&amp;displaylang=en","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"MSMQ","slug":"MSMQ","permalink":"http://stegenfeldt.github.io/tag/MSMQ/"}]},{"title":"Linux Discovery – Not Enough Entropy","slug":"linux-discovery-not-enough-entropy","date":"2009-12-02T11:37:08.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/sles/linux-discovery-not-enough-entropy/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/sles/linux-discovery-not-enough-entropy/","excerpt":"","keywords":null,"text":"Here’s a little trouble-shooting guide for discovering Linux systems from OpsMgr R2 when getting the following error from the wizard: [xml]&lt;stdout&gt;Generating certificate with hostname=&quot;COMPUTERNAME&quot; [/home/serviceb/TfsCoreWrkSpcRedhat/source/code/tools/scx_ssl_config/scxsslcert.cpp:198] Failed to allocate resource of type random data: Failed to get random data - not enough entropy &lt;/stdout&gt;&lt;stderr&gt;error: %post(scx-1.0.4-248.i386) scriptlet failed, exit status 1 &lt;/stderr&gt;&lt;returnCode&gt;1&lt;/returnCode&gt; &lt;DataItem type=&quot;Microsoft.SSH.SSHCommandData&quot; time=&quot;2009-08-05T11:15:01.5800358-04:00&quot; sourceHealthServiceId=&quot;0EB1D6DA-202C-7FC5-3D46-BDBB9208547D&quot;&gt;&lt;SSHCommandData&gt;&lt;stdout&gt;Generating certificate with hostname=&quot;COMPUTERNAME&quot; [/home/serviceb/TfsCoreWrkSpcRedhat/source/code/tools/scx_ssl_config/scxsslcert.cpp:198] Failed to allocate resource of type random data: Failed to get random data - not enough entropy &lt;/stdout&gt;&lt;stderr&gt;error: %post(scx-1.0.4-248.i386) scriptlet failed, exit status 1 &lt;/stderr&gt;&lt;returnCode&gt;1&lt;/returnCode&gt;&lt;/SSHCommandData&gt;&lt;/DataItem&gt; [/xml] But first, a little background on the actual “problem”. To generate the certificate, the entropy needs to be high enough to generate random data for the certificate creation. Without the certificate, the OpsMgr agent won’t be able to open up communications with the MS. So, what creates this entropy we need? Bluntly put, a selection of hardware components that are likely to produce non-predictable data. Like a keyboard, mouse and a monitor or videocard. Of course, there’s a lot more to it, but we really don’t need to know this. What we need to know is that there has to be a “bit bucket” of more than 256bytes of entropy for the certificate creation process to succeed. We also need to know that more enterprise-ish servers, like rack- or blade-servers tend to be void of things like directly attached keyboards, mouses and monitors that the linux kernel needs to be able to generate entropy. And herein lies the problem. If you have a new server that is not in full service (likely since we are trying to deploy the monitoring on it) which means that there’s not much random data flowing through the hardware and there’s no keyboard or mouse or monitor connected to it there is quite the risk that the system entropy is going to be very low. Of the linux systems that I have been deploying OpsMgr agents to, about half have failed because of “Not enough entropy”. So, here’s the steps I usually takes to ensure that discovery works. I use PuTTY to connect to the soon-to-be-monitored servers. This guide also assumes that you have SU rights on the system since all of these steps (except #1) needs it. Check you current entropy[plain]cat /proc/sys/kernel/random/entropy_avail[/plain] Is it less than, or close to, 256? It probably is. If you don’t feel like connecting a mouse and start wiggling it around—not really feasible in a data center—and see if the entropy increases, you can generate your own random data. Generate you own random data.Be advised that this forced entropy will not be as random as the system-created on and thus not as secure. How much more insecure it is, I don’t know, and quite frankly I prefer to have my systems monitored yet slightly less secure than not monitored at all. Anyway, you can force your own random data by running:[plain]dd if=/dev/urandom of=~/.rnd bs=1 count=1024[/plain] This creates a .rnd file with 1024B of random data that the certificate creation process will use instead of the system entropy if the file exists. Uninstall and re-discoverThe first failed attempt of discovery will most likely leave a non-working agent installation that we have to remove. Otherwise we will just be stuck with an “Access Denied” error. Run:[plain]rpm –e scx[/plain] Now, try to discover the system again. Failed again?Try generating the certificate manually by running:[plain]/opt/microsoft/scx/bin/tools/scxsslconfig -f –v/opt/microsoft/scx/bin/tools/scxadmin –restart[/plain] Retry discovery again. Still fails?Uninstall the agent once more as instructed in step 3.Stese steps have solved my problems 100% on both SUSE and RedHat and hopefully they will help you too. Interestingely enough, these problems seems to be connected to some changes in the 2.6 kernel and basically everything that uses SSL-ish certificates will be affected. Even though the symptoms may be a bit more subtle, like time-outs and disconnects. For “headless” servers like those I usually to administer where the random data tend to be much lower, there’s even specialised hardware whose sole purpose is to generate random data, like the Entropy Key. I have also been told that new servers is likely to be equipped with entropy chipsets to make sure that there’s chaos enough to avoid these new-found oddities. Sources:http://social.technet.microsoft.com/Forums/en-US/crossplatformsles/thread/f94ec905-23ac-4444-b9f8-644fec3ae357 http://www.askrenzo.com/oracle/SCOM/SCOM_discovering_nodes.html","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"SLES","slug":"opsmgr2007/sles","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/sles/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/tag/Linux/"},{"name":"TroubleShooting","slug":"TroubleShooting","permalink":"http://stegenfeldt.github.io/tag/TroubleShooting/"},{"name":"X-Plat","slug":"X-Plat","permalink":"http://stegenfeldt.github.io/tag/X-Plat/"}]},{"title":"(re)Gain sysadmin access to SQL2005 or SQL2008","slug":"regain-sysadmin-access-to-sql2005-or-sql2008","date":"2009-11-19T13:08:10.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/sql2005/sql2008/regain-sysadmin-access-to-sql2005-or-sql2008/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/sql2005/sql2008/regain-sysadmin-access-to-sql2005-or-sql2008/","excerpt":"","keywords":null,"text":"In SQL Server 2005 and 2008 the local Administrators account is not sysadmin by default. This makes it even more important that the one setting up the Database also remembers to add a SQL Server admins group to the sysadmin role. If this step is forgotten, the user installing the database server is the only one that will ever be sysadmin. In some extreme cases I’ve seen situations where no one except some dude on vacation is sysadmin and I need to install or upgrade a bunch of applications and services. In these cases I have also been assigned Local Administrator rights on the server, but since the local Administrators group isn’t sysadmin either I still cannot login to the SQL server.What to do!? Thanks to Raul Carcia’s blog post it’s not that a big deal. The instructions are written for SQL Server 2005 but works equally fine on SQL Server 2008 and the only pre-requirement is that you are a local server administrator.Here’s what to do: Open the SQL Server Configuration Manager. In SQL Server Services, open the properties for the SQL Server instance you need access to. In the Advanced tab, find Startup Parameters. Add “;-m” to the end of that line. Press OK and restart the SQL Server into “Maintenance Mode” or “Single User Mode” if you like. (check that a restart is OK first ;)) Open a command prompt (right-click, “Run as Administrator” in Windows 2008) and go to C:\\Program Files\\Microsoft SQL Server\\100\\Tools\\Binn(C:\\Program Files\\Microsoft SQL Server_90_\\Tools\\Binn for SQL2005) Execute[plain]sqlcmd /A /E /S &lt;INSTANCE&gt;[/plain] (use . for local default instance and .INSTANCE for local named instance) In the CLI, execute:[sql]EXEC sp_addsrvrolemember ‘DOMAIN\\yourusername’, ‘sysadmin’;GO[/sql] Return to the SQL Server Configuration Manager and restore the Startup Parameters to it’s previous settings. Restart the SQL Server instance to allow users to get access to it again.Now, you should be able to login to the SQL server with sysadmin rights using your current user. This would also be a good time to actually set up a SQL Server Admins group (local or domain) to add to the sysadmin role to avoid having others to the above steps when you, yourself, are on vacation. ;) As Raul Carcia point out in his original post, this is really a disaster recovery procedure and there’s definitely nothing sneaky about it since it leaves a lot of trails in the event logs. All in all, a Great article by Raul and all credit should go his way.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"SQL 2005","slug":"opsmgr2007/sql2005","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/sql2005/"},{"name":"SQL 2008","slug":"opsmgr2007/sql2005/sql2008","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/sql2005/sql2008/"}],"tags":[{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"SQL Server","slug":"SQL-Server","permalink":"http://stegenfeldt.github.io/tag/SQL-Server/"},{"name":"SQL Server 2005","slug":"SQL-Server-2005","permalink":"http://stegenfeldt.github.io/tag/SQL-Server-2005/"},{"name":"SQL Server 2008","slug":"SQL-Server-2008","permalink":"http://stegenfeldt.github.io/tag/SQL-Server-2008/"}]},{"title":"Updated: MP for System Center Configurations Manager 2007 SP2 on x64","slug":"updated-mp-for-system-center-configurations-manager-2007-sp2-on-x64","date":"2009-11-03T11:13:00.000Z","updated":"2016-05-19T09:11:09.327Z","comments":true,"path":"opsmgr2007/updated-mp-for-system-center-configurations-manager-2007-sp2-on-x64/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/updated-mp-for-system-center-configurations-manager-2007-sp2-on-x64/","excerpt":"","keywords":null,"text":"Microsoft has released an updated MP for SCCM SP2 (v6.0.6000.2, released on 10/28/2009) for OpsMgr R2. The update basically contains support for x64 that was missing in the previous release. The Configuration Manager 2007 SP2 Management Pack adds support for monitoring Configuration Manager 2007 SP2 in a 64-bit environment with Operations Manager 2007 R2 or Operations Manager 2007 SP1 with hotfix (KB971541) installed. This enables the Configuration Manager 2007 SP2 Management Pack to work with either the 32-bit or the 64-bit Operations Manager 2007 agent. Except for the 64-bit support, the other features and guidance for Configuration Manager 2007 Management Packs remain intact.(coloration added by me) Read more and download here:http://www.microsoft.com/downloads/details.aspx?FamilyID=a8443173-46c2-4581-b3b8-ce67160f627b","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"x64","slug":"x64","permalink":"http://stegenfeldt.github.io/tag/x64/"}]},{"title":"Installing SQL Reporting Services 2005 on Windows 2008 x64","slug":"installing-sql-reporting-services-2005-on-windows-2008-x64","date":"2009-11-02T13:33:27.000Z","updated":"2016-05-19T09:11:09.326Z","comments":true,"path":"opsmgr2007/sql2005/sql2008/installing-sql-reporting-services-2005-on-windows-2008-x64/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/sql2005/sql2008/installing-sql-reporting-services-2005-on-windows-2008-x64/","excerpt":"","keywords":null,"text":"Let’s say you have followed this guide: http://support.microsoft.com/kb/938245/ Still not working? The one thing I forgot, or rather did not find in any of the guides, was to change the website application pool to “Classic .NET AppPool”. It is actually noted in KB938245 but only after the installation, during the configuration. For some reason I have not been able to install Reporting Services 2005 on Windows 2008 without changing this prior to the installation. Maybe I am doing it wrong but this seems to be working all right for me.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"SQL 2005","slug":"opsmgr2007/sql2005","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/sql2005/"},{"name":"SQL 2008","slug":"opsmgr2007/sql2005/sql2008","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/sql2005/sql2008/"}],"tags":[{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"},{"name":"IIS7","slug":"IIS7","permalink":"http://stegenfeldt.github.io/tag/IIS7/"},{"name":"Reporting Services","slug":"Reporting-Services","permalink":"http://stegenfeldt.github.io/tag/Reporting-Services/"},{"name":"x64","slug":"x64","permalink":"http://stegenfeldt.github.io/tag/x64/"}]},{"title":"Cannot Delete Files with Long Paths?","slug":"cannot-delete-files-with-long-paths","date":"2009-10-21T07:39:17.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"ms/win2008/winvista/winxp/cannot-delete-files-with-long-paths/","link":"","permalink":"http://stegenfeldt.github.io/ms/win2008/winvista/winxp/cannot-delete-files-with-long-paths/","excerpt":"","keywords":null,"text":"What do you do when you cannot delete a file or folder on a windows server? Check the file permissions! And if that doesn’t help? Check the share permissions! Yes, if it is a shared folder. And if that doesn’t help? Check the file ownership! Great! But then what? Well, the file could be in use, and then you would have to shut the locking process down and perhaps kick a user out. In a really bad scenario it could also be a symptom of a broken filesystem, a reserved filename (like “lpt1” or “PRN”) or even an invalid name (silly things like a space in the beginning or the end of a filename).Another possible reason could actually be that the path to the file or folder is too long. You won’t actually get an error telling you that the filepath exceeds the 255 characters Windows can handle but a simple “Acces Denied”. There are some, more or less tedious, work-arounds for the problem. Like renaming, starting from the root, all the directories to shorter ones or using the old DOS (8.3, like “dokume~1.doc”) names that windows can auto-generate for you. Personally, I have two favourite ways of handling this. Map the parent-directory of the file/folder you are trying to access/delete as a network drive and access your files that way.This is particularly useful if the folder you are trying to access a DFS-share or perhaps a share on the central fileserver filepaths like “\\servername01Central ProjectsCentral ServicesIT DepartmentDevelop Methods for Automatically Deploying New Central Servers2.2.1 Auto-Deploying SQL-Server 2005 ClusterDocumentsPreparationsWhitepapersSQL Server 2005 Failover Clustering White Paper.doc” Create a new share to a folder further down the hierarchy. This works locally too if you are logged on to, say, SRV01, you create a new share on “D:FilesharesCentral ProjectsCentral ServicesIT DepartmentDevelop Methods for Automatically Deploying New Central Servers” called “Autodeploymethods” and access it from “\\SRV01Autodeploymethods”. That way the filepath doesn’t exceed 255 characters.Now. When designing fileservers, you really should think about how deep the filepaths may get. This is especially true on DFS-shares since you might have to deal with the full FQDN too, and not only the actual folder structure. Many big corporations I know uses “codes” for departments and assign a project ID (quite simply a number or maybe an abbreviation) to each project and uses theese for the fileshares too. Another scenario that could lead to similar problems are intranet sites where users can create and manage their own subsites and where filenames and folders are not stored in a database. I have only seen this phenomena on Windows systems so far, and I’ve actually used a linux Live-CD on occasion when admin access is denied. Read More:http://support.microsoft.com/kb/320081","raw":null,"content":null,"categories":[{"name":"Microsoft","slug":"ms","permalink":"http://stegenfeldt.github.io/topics/ms/"},{"name":"Windows 2008","slug":"ms/win2008","permalink":"http://stegenfeldt.github.io/topics/ms/win2008/"},{"name":"Windows Vista","slug":"ms/win2008/winvista","permalink":"http://stegenfeldt.github.io/topics/ms/win2008/winvista/"},{"name":"Windows XP","slug":"ms/win2008/winvista/winxp","permalink":"http://stegenfeldt.github.io/topics/ms/win2008/winvista/winxp/"}],"tags":[{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"KB","slug":"KB","permalink":"http://stegenfeldt.github.io/tag/KB/"},{"name":"Windows","slug":"Windows","permalink":"http://stegenfeldt.github.io/tag/Windows/"}]},{"title":"Microsoft Adds support for SUSE 11 in OpsMgr R2","slug":"microsoft-adds-support-for-suse-11-in-opsmgr-r2","date":"2009-10-16T05:59:10.000Z","updated":"2016-05-19T09:11:09.326Z","comments":true,"path":"opsmgr2007/microsoft-adds-support-for-suse-11-in-opsmgr-r2/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/microsoft-adds-support-for-suse-11-in-opsmgr-r2/","excerpt":"","keywords":null,"text":"This update hasn’t showed up in the MP Catalog yet, but the System Center Operations Manager 2007 R2 Cross Platform Update can be downloaded here. Besides SUSE 11 support, here’s the short overview. The System Center Operations Manager 2007 R2 Cross Platform Update adds fixes for a defunct process issue on Unix/Linux Servers, as well as, adds support for SUSE Linux Enterprise Server 11 (both 32-bit and 64-bit versions) and Solaris Zone support.Feature Summary:The System Center Operations Manager 2007 R2 Cross Platform Update supports the monitoring of Unix/Linux Servers including: Monitoring of SUSE Linux Enterprise Server 11 servers (both 32-bit and 64-bit versions) Support of Solaris Zones Fix for defunct Process issue The Cross Platform Agent may not discover soft partitions on Solaris systems. Therefore, the disk provider may be unloaded, and the Cross Platform Agent may stop collecting information from the system disks. The Cross Platform Agent may not restart after the AIX server reboots. The latest versions of all the Operations Manager 2007 R2 Unix/Linux agents are included in this update. Perfect timing, I must say, since I really need this today. :D Update:This is no small MP-update, which probably is the reason that we do not find it in the MP Catalog, but a ~250MB OpsMgr R2 Software Update. You need to run this on all Operations Manager Servers (RMS/MS, GW?) since it actually updates many of the agent Cross Platform binaries. It does add a new MP för SUSE 11 that you have to import from disk if you need it. So, the installation goes somewhat like this: Install the Software Update (pick the right Architecture) on all OpsMgr R2 Servers Import the SUSE 11 MP if necessary Re-discover your Unix/Linux machines. Files updated in this update for R2: .Microsoft.Enterprisemanagement.UI.Administration.dll (Version 6.1.7043.1) .AgentManagementUnixAgentsscx-1.0.4-248.aix.5.ppc.lpp.gz .AgentManagementUnixAgentsscx-1.0.4-248.aix.6.ppc.lpp.gz .AgentManagementUnixAgentsscx-1.0.4-248.hpux.11iv2.ia64.depot.Z .AgentManagementUnixAgentsscx-1.0.4-248.hpux.11iv2.parisc.depot.Z .AgentManagementUnixAgentsscx-1.0.4-248.hpux.11iv3.ia64.depot.Z .AgentManagementUnixAgentsscx-1.0.4-248.hpux.11iv3.parisc.depot.Z .AgentManagementUnixAgentsscx-1.0.4-248.rhel.4.x64.rpm .AgentManagementUnixAgentsscx-1.0.4-248.rhel.4.x86.rpm .AgentManagementUnixAgentsscx-1.0.4-248.rhel.5.x64.rpm .AgentManagementUnixAgentsscx-1.0.4-248.rhel.5.x86.rpm .AgentManagementUnixAgentsscx-1.0.4-248.sles.10.x64.rpm .AgentManagementUnixAgentsscx-1.0.4-248.sles.10.x86.rpm .AgentManagementUnixAgentsscx-1.0.4-248.sles.9.x86.rpm .AgentManagementUnixAgentsscx-1.0.4-248.solaris.10.sparc.pkg.Z .AgentManagementUnixAgentsscx-1.0.4-248.solaris.10.x86.pkg.Z .AgentManagementUnixAgentsscx-1.0.4-248.solaris.8.sparc.pkg.Z .AgentManagementUnixAgentsscx-1.0.4-248.solaris.9.sparc.pkg.Z Files added: Microsoft.Linux.SLES.11.MP All in all, the update contains the following fixes: KB969342 KB973583 Q954049 Q956240","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"X-Plat","slug":"X-Plat","permalink":"http://stegenfeldt.github.io/tag/X-Plat/"},{"name":"SUSE 11","slug":"SUSE-11","permalink":"http://stegenfeldt.github.io/tag/SUSE-11/"}]},{"title":"Health Rollup not working in Exchange Management Pack","slug":"health-rollup-not-working-in-exchange-management-pack","date":"2009-10-14T10:17:08.000Z","updated":"2016-05-19T09:11:09.326Z","comments":true,"path":"opsmgr2007/health-rollup-not-working-in-exchange-management-pack/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/health-rollup-not-working-in-exchange-management-pack/","excerpt":"","keywords":null,"text":"I’ve wrestled a bit with a critical status on one of the Organization States at a clients site that wont go back to green despite all the underlying monitors have gone back to green. And apparently I am not alone on this one. Others, like me, has read and re-read the MP-guide i search for a monitor/rule/discovery for overrides forgotten, and I don’t know how many times I’ve made a small change and tried resetting the health once again. Anyhow.Marius Sutara posted an answer on TechNet forums last week with a “fix” (-ish), or rather the acknowledgement that the problem is not a 40c. The problem might be related to other MP as well, but I’ve only seen it on the new Exchange MP so far. In that same post, Pete Zerger provided some links to two nifty little tools that will help you reset the health of the monitor. In case you wonder why on earth I post when there’s allready a “solution” out there; Pagerank, baby!Not for me, but for the forum post making it show up earlier on google.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"Exchange","slug":"Exchange","permalink":"http://stegenfeldt.github.io/tag/Exchange/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"TechNet","slug":"TechNet","permalink":"http://stegenfeldt.github.io/tag/TechNet/"}]},{"title":"Updated: Operations Manager 2007 R2 Management Pack","slug":"updated-operations-manager-2007-r2-management-pack","date":"2009-10-14T09:29:00.000Z","updated":"2016-05-19T09:11:09.326Z","comments":true,"path":"opsmgr2007/updated-operations-manager-2007-r2-management-pack/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/updated-operations-manager-2007-r2-management-pack/","excerpt":"","keywords":null,"text":"Microsoft released an updated MP (v6.1.7533.0, released on 10/8/2009) for monitoring the health the Operations Manager components. Most significant updates, according to me, would seem to be: Fixed an issue that was previously preventing all rules related to agentless exception monitoring from generating alerts. &gt; Added the rule “Collects Opsmgr SDK ServiceClient Connections” to collect the number of connected clients for a given management group. This data is shown in the view “Console and SDK Connection Count” under the folder “Operations ManagerManagement Server Performance”. &gt; Updated a number of monitors and rules to ensure that data is reported to the correct management group for multihomed agents. &gt; Fixed the configuration of the rule “IIS Discovery Probe Module Execution Failure” to so that the parameter replacement will now work correctly for alert suppression and generating the details of the alert’s description. The rest is mostly polishing, fine-tuning and complementary updates. Nothing really ground-breaking here, but still a welcome update. Download at: http://www.microsoft.com/downloads/details.aspx?FamilyID=61365290-3c38-4004-b717-e90bb0f6c148","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"}]},{"title":"SQL ManagementPack Survey – Make your voice heard","slug":"sql-managementpack-survey-make-your-voice-heard","date":"2009-10-07T12:24:37.000Z","updated":"2016-05-19T09:11:09.326Z","comments":true,"path":"opsmgr2007/sql-managementpack-survey-make-your-voice-heard/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/sql-managementpack-survey-make-your-voice-heard/","excerpt":"","keywords":null,"text":"According to the OpsMgr Team blog, Microsoft wants to know what you think about their SQL Server MP. It’s really hard to come by a better opportunity to express your feelings and desires about monitoring SQL Server, so don’t miss this one out. http://blogs.technet.com/momteam/archive/2009/09/25/sql-management-pack-survey-live-on-connect.aspx","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"SQL Server","slug":"SQL-Server","permalink":"http://stegenfeldt.github.io/tag/SQL-Server/"}]},{"title":"Replace/Change a Gateway Server","slug":"replacechange-a-gateway-server","date":"2009-09-24T10:32:35.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"opsmgr2007/PoSH/replacechange-a-gateway-server/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/PoSH/replacechange-a-gateway-server/","excerpt":"","keywords":null,"text":"If you are looking into replacing an (or just switching to another primary) Operations Manager 2007 Gateway Server for any reason, there’s a little more to consider than just right-clicking the clients and selecting “Change Primary Management Server” in the Operations Console.You could end up with agents not being able to connect to the Management Group at all due to a small problem with the order in which Operations Manager do things. Here’s basically what happens: You tell Operations Manager to change Primary Management Server for AGENTX from GW1 to GW2. The SDK Service (i guess) tells GW1 that “You’re no longer the Primary Management Server for AGENTX” GW1 acknowledges this and stops talking to AGENTX. And I mean Completely stops talking to AGENTX. OpsMgr then tells GW2 to start accepting communication from AGENTX. OpsMgr tries to tell AGENTX that it should talk to GW2 since GW1 won’t listen.Spotted the problem?This modus operandi probably works when agents are on the same network and in the same domain where fail-over is sort of automatic. The problem we are facing now is that the server are telling the Gateway to stop accepting communications to and from the agent before the agent is notified that there is a new Gateway server to talk to. The agent will continue to talk to GW1 but will be completely ignored and you will probably start seeing events in the Operations Manager eventlog on GW1 with EventID 20000. How do I get around this little feature then? No matter if you found this article after running into the mentioned troubles or if you are googling ahead of time to be prepared, the fix is the same and consists of a few powershell scripts. These scripts are out there allready, but in different contexts, hence this post. First step: Install the new GatewayDocumentation on this from Microsoft is good enough, but here’s the short version. Verify name resolution to and from Gateway server and Management Server Create certificate for the Gateway server Approve the Gateway server Install Gateway server Import certificates on Windows system Run MOMCertImport.exe on Gateway server to add the certificate into Gateway server configuration WaitThe wait is for the gateway server to get all needed configuration from RMS and to download all neccesary management packs, run all the discovery scripts and so on. When the Operations Manager event log has calmed down a bit, move to step two. Second step: Configure Agent FailoverConnect to an Operations Manager Command Shell. Any will do, as long as it’s connected to the correct Management Group.Then run the following script: [ps]$primaryGW= Get-ManagementServer | where {$.Name -eq ‘GW2.domain.local’}$failoverGw = Get-ManagementServer | where {$.Name -eq ‘GW1.domain.local’}$agents = Get-Agent | where {$_.primarymanagementservername -eq ‘GW1.domain.local’}Set-ManagementServer -AgentManagedComputer: $agents -PrimaryManagementServer: $primaryGW -FailoverServer: $failoverGw[/ps] Remember to change “GW1.domain.local” to you OLD Gateway servername and “GW2.domain.local” to your NEW Gateway servername.If you don’t know powershell, this script basically configures all agents using the old Gateway to use the new one as primare, but keep the old one as a fail-over server. The Gateways will still get to know the changes before the agents, but since the old on is still listening to the agents (though, as the fail-over host) it will be able to tell them to go to the new one, GW2.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"},{"name":"PoSH","slug":"opsmgr2007/PoSH","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/PoSH/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"PoSH","slug":"PoSH","permalink":"http://stegenfeldt.github.io/tag/PoSH/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"}]},{"title":"My impression of EXT4 -- WTH!?","slug":"my-impression-of-ext4-wth","date":"2009-09-17T17:43:47.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"Linux/my-impression-of-ext4-wth/","link":"","permalink":"http://stegenfeldt.github.io/Linux/my-impression-of-ext4-wth/","excerpt":"","keywords":null,"text":"Ok, so I reinstalled my linux partition with Ubuntu 9.04 x64 and decided to try EXT4 on the root partition. Like, yesterday.Managed to get the Citrix client running (way more easy on Ubuntu than Fedora, I’ll be back on that) and all without too much fuzz. First reboot gave me a “let’s FSCK!”. So I FSCK-ed and booted up to the desktop. Second reboot gave me a “let’s FSCK!”. And I did. Booted to the desktop. Third boot went smoothly, but all of a sudden all the icons decided to go AWOL. Rebooted again. Fourth boot gave me a “let’s FSCK!”. I replied with “Well FSCK You!” Fifth boot gave me a “let’s FSCK!”. I rebooted back to Windows 7. Tonight I am reinstalling Ubuntu 9.04 x64 with EXT3.","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/topics/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://stegenfeldt.github.io/tag/Linux/"},{"name":"Rant","slug":"Rant","permalink":"http://stegenfeldt.github.io/tag/Rant/"}]},{"title":"The TCP Port Check: Use with caution!","slug":"tcp-port-check-use-with-caution","date":"2009-08-27T12:39:43.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"opsmgr2007/tcp-port-check-use-with-caution/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/tcp-port-check-use-with-caution/","excerpt":"","keywords":null,"text":"Just wanted to raise a word of caution about the TCP Port Check in Operations Manager 2007. Some customers have notices the the system-logs on some Unix machines are completely swamped with “connection error”, “TCP Connect failed”, “TCP Session Lost” and similar and after a bit och research the problematic servers were narrowed down to those monitored by Operations Manager. Specifically, those who are targeted by a TCP Port Check. It would seem like the TCP-connection never fully initializes on the target server. Kind of like knocking on your neighbours door and then hiding. Then when the door opens, no one is there. Maybe there’s a setting somewhere to modify how “deep” a Port Check should go before closing. Perhaps fully initializing and then sending a proper “Close” instead of just cutting the connection. In a few extreme cases we have noticed that the target server even goes so far as to start a session, but never ending it since there’s no closure and finally having no sessions to spare for the real users. But on most servers it’s just an annoyance since the “real” errors is very hard to be found in all the connection related logs. Anyway. Just a good thing to keep in mind when running TCP Port Checks from Operations Manager 2007. Keep an eye on the logs when implementing the port checks.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"Unix","slug":"Unix","permalink":"http://stegenfeldt.github.io/tag/Unix/"}]},{"title":"Why not use SQL Express? It’s for free!","slug":"whynotusesqlexpress-itsforfree","date":"2009-08-21T08:38:55.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"sql2008/whynotusesqlexpress-itsforfree/","link":"","permalink":"http://stegenfeldt.github.io/sql2008/whynotusesqlexpress-itsforfree/","excerpt":"","keywords":null,"text":"I get this question every now and then and every time I find myself completely flabbergasted and having to look things up once again. To avoid wasting my time on the same question once again and perhaps help others doing the same, here’s a little guidance. Don’t get me wrong now.SQL Express has it’s applications and for a free database server, it’s not half-bad. Small development sites, minor, not that extremely important systems with lower performance and feature demands, minor website databases et cetera could do well with SQL Express. Here’s my list of questions you have to ask to find if SQL Express is the correct choice. Do your applications support SQL Express?If your application developers cannot say “Yes” to this, you’re out of luck. You could probably get their applications to run on SQL Express anyway, but application support if something goes bad will most likely be zilch. Do your applications fit the hardware limitations?SQL Express is limited to 1GB RAM, 1 CPU and 4GB of databases. 1GB of RAM seems a bit tight to me for any production data. Also, on SQL Express 2005, according to Microsoft, you cannot run parallel queries._”SQL Server Express can install and run on multiprocessor machines, but only a single CPU is used at any time. Internally, the engine limits the number of user scheduler threads to 1 so that only 1 CPU is used at a time. Features such as parallel query execution are not supported because of the single CPU limit.”_If this is still true on SQL Express 2008, I don’t know and I haven’t found any information about it (yet).When answering this question, remember to calculate expected growth and possibly new databases/applications too. Do your applications use database replication?If, so. Do the new server need to act as a publisher? If, yes, then you’re out of luck. SQL Express do handle database replication, but only as a subscriber. If you need to publish data, then you need a “bigger” SQL Edition. Do you need Database Mail?SQL Express does not have Database Mail. You have to find other ways to code your notifications. This question has raised counter-questions from customers as to “What would I need Database Mail for?”. It is, evidently a feature not used by many. Personally, I find it useful. Clay McDonald has a nice blog-post on how to make SQL-triggers send mail on, for instance, inserts into a table using Database Mail. You could of course have it send mail on deletions as well. In my mind, this might come in handy in user-databases in CRM- or HR-systems. Every time an employee gets deleted from the database, the HR-admin could receive a notification. Do you need the SQL Agent?Perhaps not. Maybe you feel comfortable with scheduling your database backups using the windows scheduler and homebrew scripts. Just make sure your monitoring software (or IT-personnel) discover when the script fails. An increasing amount of applications require the SQL Agent to schedule and monitor recurring tasks, like Microsoft’s App-V. Without the SQL Agent, the databases would grow ad infinitum. How about index maintenance? This is also possible to go by using your own scripts and the windows scheduler. SQL Express can do most maintenance tasks you would need using scripts and T-SQL. The SQL Agent just makes it simpler and more manageable. Once again, double-check this with the application developer. Do you application use SSIS/DTS-jobs?This is not included in SQL Express. Maybe there’s a work-around, but I haven’t found it and I doubt it is supported by anyone. Do you need to be able to troubleshoot performance problems?You can do this on SQL Express with a great deal of knowledge and timers. The SQL-profiler, the Performance Data Collection and the Database Tuning Advisor makes it easier. Specifically, the SQL-profiler comes in really handy when you suspect the application (not the system) to be the bad guy since you can trace the queries and pin-point where the performance-hit resides. Using the SQL-profiler I have been able to optimise indexes to and thus making database servers go from a 98% CPU Load to 3% CPU Load. I have also been able to pin-point specific queries and use them as “evidence” that the problem is bad/sloppy code rather than problems with the database server. Also, using the SQL-profiler.There’s more, of course, but these point are the most common pit-falls in my experience. As you can see, there’s three “do you need”-questions and there are highly optional. Far from everyone use them and often because of lacking SQL Server knowledge. You don’t know what you can do. Still, the most important question is #1. Is SQL Express a supported database server for your applications. Hopefully, the developer knows the answer to this directly. No maybe’s. Yes or No. Personally, I find that If you need a database server for production data, don’t go for SQL Express. Many customers have gone that way because “it’s free!” just to find themselves in the midst of a SQL Server upgrade and database migration a year later.","raw":null,"content":null,"categories":[{"name":"SQL 2008","slug":"sql2008","permalink":"http://stegenfeldt.github.io/topics/sql2008/"}],"tags":[{"name":"Checklist","slug":"Checklist","permalink":"http://stegenfeldt.github.io/tag/Checklist/"},{"name":"SQL Express 2005","slug":"SQL-Express-2005","permalink":"http://stegenfeldt.github.io/tag/SQL-Express-2005/"},{"name":"SQL Express 2008","slug":"SQL-Express-2008","permalink":"http://stegenfeldt.github.io/tag/SQL-Express-2008/"}]},{"title":"MSMQ Management Pack: Subscript Out of Range","slug":"msmq-mp-subscriptoutofrange","date":"2009-06-24T07:51:01.000Z","updated":"2016-05-19T09:11:09.324Z","comments":true,"path":"opsmgr2007/msmq-mp-subscriptoutofrange/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/msmq-mp-subscriptoutofrange/","excerpt":"","keywords":null,"text":"UPDATE: This problem seems to be fixed in the latest update! The MSMQ Management Pack seems to have a few problems with it’s discovery script that can lead to the following error showing up in the logs: [plain]The process started at 13:34:40 failed to create System.Discovery.Data. Errors found in output: C:Program FilesSystem Center Operations Manager 2007Health Service StateMonitoring Host Temporary Files 499788DiscoverQueues.vbs(107, 4) Microsoft VBScript runtime error: Subscript out of range: ‘[number: 0]’ Command executed: &quot;C:WINDOWSsystem32cscript.exe&quot; /nologo &quot;DiscoverQueues.vbs&quot; {615D37C9-477D-62E2-0833-6ECBF0E89A87} {A176AC83-CC31-01C3-5DE9-E2DFF64E7CC7} &quot;MASKED.server.fqdn&quot; &quot;MSMQ&quot; &quot;true&quot; &quot;true&quot; &quot;False&quot; &quot;false&quot;Working Directory: C:Program FilesSystem Center Operations Manager 2007Health Service StateMonitoring Host Temporary Files 499788 One or more workflows were affected by this. Workflow name: Microsoft.MSMQ.2003.DiscoverQueues Instance name: MASKED.server.fqdn Instance ID: {A176AC83-CC31-01C3-5DE9-E2DFF64E7CC7} Management group: MASKED[/plain] This seems to be related to the discovery of public queues on some servers that has none. One quick fix, or rather work-around, is to override the discovery on these servers to set DiscoverPublic to False.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"MSMQ","slug":"MSMQ","permalink":"http://stegenfeldt.github.io/tag/MSMQ/"},{"name":"Fixed","slug":"Fixed","permalink":"http://stegenfeldt.github.io/tag/Fixed/"},{"name":"Quick-fix","slug":"Quick-fix","permalink":"http://stegenfeldt.github.io/tag/Quick-fix/"}]},{"title":"Windows Server 2008 NLB MP for OpsMgr released","slug":"windows-server-2008-nlb-m-for-opsmgr-released","date":"2009-04-29T10:59:54.000Z","updated":"2016-05-19T09:11:09.324Z","comments":true,"path":"opsmgr2007/windows-server-2008-nlb-m-for-opsmgr-released/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/windows-server-2008-nlb-m-for-opsmgr-released/","excerpt":"","keywords":null,"text":"Don’t know how I missed this when writing the last post, but Microsoft released the MP for Windows Server 2008 NLB yesterday (28/4 -09). This is the initial release for Win2k8 NLB so I guess we just have to try it out then. Quick DetailsFile Name:Microsoft Server 2008 Network Load Balancing System Center Operations Manager 2007 MP.msiVersion:6.0.6573.0Date Published:4/28/2009Language:EnglishDownload Size:519 KB Feature Summary Monitor the NLB Node status. Based on the status of individual cluster nodes, determine the overall state of the cluster. Where an integration management pack exists, determine the health state of a cluster node by looking at the health state of the load balanced application, such as IIS. Alert on errors and warnings that are reported by the NLB driver, such as an incorrectly configured NLB cluster. Take the node out of the NLB cluster if the underlying load-balanced application becomes unhealthy, and add the node back to the cluster when the application becomes healthy again.Requires OpsMgr 2007 SP1 or later, the Base Operating System MP for 2008, the QFEs for Windows Server 2008 and that you are not running the converted 2003 NLB MP. If you are running the old converted NLB MP, upgrade first. As an additional recommendation, Microsoft recommends in the MP Guide that you install the QFE for wmiprvse.exe problems on Windows Server 2008. No support for Mixed-mode (2008 and 2003) clusters though.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"}]},{"title":"MSMQ 3 MP for OpsMgr v.6.0.6587.0 Released","slug":"msmq-3-mp-for-opsmgr-v6065870-released","date":"2009-04-28T13:30:18.000Z","updated":"2016-05-19T09:11:09.324Z","comments":true,"path":"opsmgr2007/msmq-3-mp-for-opsmgr-v6065870-released/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/msmq-3-mp-for-opsmgr-v6065870-released/","excerpt":"","keywords":null,"text":"Last friday, 24/4 -09,&#160; Microsoft released an updated Management Pack for MSMQ 3.0. Quick Details File Name: Message Queuing System Center Operations Manager 2007 MP.MSI Version: 6.0.6587.0 Date Published: 4/24/2009 Language: English Download Size: 502 KB Release History 6/3/2008 - Initial Release, version 6.0.6278.23. Refer to the MP guide for further details.* 4/24/2009 - Undated release, version 6.0.6587.0. Refer to the MP guide for further details. The MP Guide does not really say much about what’s updated and I don’t know how much more than the reporting they have fixed. I can just state the fact that support for clustered MSMQ 3 instances is still missing.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"},{"name":"MSMQ","slug":"MSMQ","permalink":"http://stegenfeldt.github.io/tag/MSMQ/"}]},{"title":"NetworkAdapterCheck.vbs fails on Windows 2000","slug":"networkadaptercheck-fails-on-win2k","date":"2009-04-26T09:21:18.000Z","updated":"2016-05-19T09:11:09.324Z","comments":true,"path":"opsmgr2007/networkadaptercheck-fails-on-win2k/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/networkadaptercheck-fails-on-win2k/","excerpt":"Here’s my summary of the problems with the NetworkAdapterCheck.vbs script in the Windows Server 2000 Operating System Management Pack för Operations Manager 2007 that is causing the failed to create System.PropertyBagData error i wrote about earlier.This information in also available on https://connect.microsoft.com/feedback/ViewFeedback.aspx?FeedbackID=432627&amp;SiteID=446 SymptomsThis “research” comes from getting an obscene amounts of Script or Executable Failed to run in the Operations Console. Each time it was the NetworkAdapterCheck.vbs script that could not create PropertyBagData. The error message copied from one of the alerts looks like this: [plain light=”true”]The process started at 14:29:26 failed to create System.PropertyBagData, no errors detected in the output. The process exited with 0 Command executed: &amp;quot;C:WINNTsystem32cscript.exe&amp;quot; /nologo &amp;quot;NetworkAdapterCheck.vbs&amp;quot; MASKEDCOMPUTERNAME 0 false true falseWorking Directory: C:Program FilesSystem Center Operations Manager 2007Health Service StateMonitoring Host Temporary Files 2882781 One or more workflows were affected by this. Workflow name: Microsoft.Windows.Server.2000.NetworkAdapter.NetworkAdapterConnectionHealthInstance name: 0Instance ID: {F4C478D3-38E5-8C29-3957-E3B7F486216E}Management group: MASKED[/plain] This error repeats almost as often as the script is scheduled to run and appears on almost every Windows 2000 server.","keywords":null,"text":"Here’s my summary of the problems with the NetworkAdapterCheck.vbs script in the Windows Server 2000 Operating System Management Pack för Operations Manager 2007 that is causing the failed to create System.PropertyBagData error i wrote about earlier.This information in also available on https://connect.microsoft.com/feedback/ViewFeedback.aspx?FeedbackID=432627&amp;SiteID=446 SymptomsThis “research” comes from getting an obscene amounts of Script or Executable Failed to run in the Operations Console. Each time it was the NetworkAdapterCheck.vbs script that could not create PropertyBagData. The error message copied from one of the alerts looks like this: [plain light=”true”]The process started at 14:29:26 failed to create System.PropertyBagData, no errors detected in the output. The process exited with 0 Command executed: &amp;quot;C:WINNTsystem32cscript.exe&amp;quot; /nologo &amp;quot;NetworkAdapterCheck.vbs&amp;quot; MASKEDCOMPUTERNAME 0 false true falseWorking Directory: C:Program FilesSystem Center Operations Manager 2007Health Service StateMonitoring Host Temporary Files 2882781 One or more workflows were affected by this. Workflow name: Microsoft.Windows.Server.2000.NetworkAdapter.NetworkAdapterConnectionHealthInstance name: 0Instance ID: {F4C478D3-38E5-8C29-3957-E3B7F486216E}Management group: MASKED[/plain] This error repeats almost as often as the script is scheduled to run and appears on almost every Windows 2000 server. Cause?I am not really sure, but after a quite a bit of troubleshooting I am pretty sure it all boils down to a malformed WMI-query. What I basically did was to extract the script from the MP and dry-run it to see if I could find anything obvious, which I didn’t.Since I didn’t have a good debugging too available, like in PrimalScript, I added the VBS equivalent of old-school printf debugging. I basically added [vb light=”true”]wscript.echo &amp;quot;Line XX:&amp;quot; &amp;amp; Err.Number[/vb] after each object/function call in the Main Sub.The problem seems to be at line 118: [vb light=”true”]Set WMISet = WMIGetInstance(&amp;quot;winmgmts:&amp;quot; + TargetComputer + &amp;quot;rootcimv2&amp;quot;, query)[/vb] At line 119 I had a debug line that never executes and it would seem like the script is unable to process the query and exits without any error codes. The query variable contains the following: [sql light=”true”]Win32_NetworkAdapter Where DeviceID=’0’ And ( NetConnectionStatus = ‘0’ )[/sql] When I was debugging this I started the script like this: [shell light=”true”]cscript.exe /nologo &amp;quot;NetworkAdapterCheck.vbs&amp;quot; MASKED 0 false true false[/shell] I did find that if I change the parameters to this: [shell light=”true”]cscript.exe /nologo &amp;quot;NetworkAdapterCheck.vbs&amp;quot; MASKED 0 false false false[/shell] Then the script runs smoothly and produces an XML-output like this: [xml light=”true”]&amp;lt;Collection&amp;gt;&amp;lt;DataItem type=&amp;quot;System.PropertyBagData&amp;quot; time=&amp;quot;2009-04-22T15:03:44.6495202+02:00&amp;quot; sourceHealthServiceId=&amp;quot;C9F5A9F7-00A3-8A86-57B5-34FB634471A8&amp;quot;&amp;gt;&amp;lt;Property Name=&amp;quot;State&amp;quot; VariantType=&amp;quot;8&amp;quot;&amp;gt;GOOD&amp;lt;/Property&amp;gt;&amp;lt;/DataItem&amp;gt;&amp;lt;/Collection&amp;gt;[/xml] CommentsThere’s quite the lot of similar errors posted on various forums on the internet but most of them ends up pointing towards the Antivirus Software as the perp and we have tried various exceptions on the server like excluding HealthExplorer.exe, MonitoringHost.exe and also the entire Health Service State folder with no improvement. But since I was able to run the scripts from other locations (not excluded) on the same server I find it hard to believe that the AV would be blocking it.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"},{"name":"Errors","slug":"Errors","permalink":"http://stegenfeldt.github.io/tag/Errors/"},{"name":"Management Pack","slug":"Management-Pack","permalink":"http://stegenfeldt.github.io/tag/Management-Pack/"}]},{"title":"Clearing Disabled Discovery in OpsMgr 2007","slug":"clearing-disabled-discovery","date":"2009-04-20T08:15:15.000Z","updated":"2016-05-19T09:11:09.320Z","comments":true,"path":"opsmgr2007/clearing-disabled-discovery/","link":"","permalink":"http://stegenfeldt.github.io/opsmgr2007/clearing-disabled-discovery/","excerpt":"","keywords":null,"text":"Jonathan Almquist has posted (a while ago) an article on how to clear discovered objects after you have disabled the discovery rules in OpsMgr that I think deserves a notion. Read more about it at Jonathan Almquist on Operations Manager : Remove-DisabledMonitoringObject.","raw":null,"content":null,"categories":[{"name":"OpsMgr 2007","slug":"opsmgr2007","permalink":"http://stegenfeldt.github.io/topics/opsmgr2007/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"},{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"},{"name":"How-To","slug":"How-To","permalink":"http://stegenfeldt.github.io/tag/How-To/"}]},{"title":"Let's split!","slug":"lets-split","date":"2009-04-16T01:27:06.000Z","updated":"2016-05-19T09:11:09.325Z","comments":true,"path":"tb/lets-split/","link":"","permalink":"http://stegenfeldt.github.io/tb/lets-split/","excerpt":"","keywords":null,"text":"Now would you look at that. Since my old site, Tranquillity.se, got messy and unfocused I have now started a new one. That’s right, you’re looking at it. Instead of blogging about mostly anything like I did before I have decided to split it into Three sites. This one for the Technical stuff, some other site I haven’t set up yet, and a personal blogg for the… personal blogging… stuff. When time gives, I will import the old tech-related posts from Tranquillity.se into this site but for now. Nothing yet so far. Have a nice day!","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[]},{"title":"NVidia problems in Ubuntu 8.10","slug":"nvidia-problems-in-ubuntu-810","date":"2008-11-10T08:20:14.000Z","updated":"2016-05-19T09:11:09.324Z","comments":true,"path":"ubuntu/nvidia-problems-in-ubuntu-810/","link":"","permalink":"http://stegenfeldt.github.io/ubuntu/nvidia-problems-in-ubuntu-810/","excerpt":"","keywords":null,"text":"[updated, scroll down if you want to skip some nonsense] So, I did an upgrade to Ubuntu Studio 8.10 (basically Ubuntu with rt-kernel and lots of nice media-related packages easily accessible and a skin that rocks) from the earlier 8.04. And the upgrade itself was really easy. I just opened the “Software Sources”, set the Release upgrade to Normal Releases (you find it under the Updates tab).After that you get the option to do a Distribution Upgrade, which I did (took some 45 minutes to finish). I did however run into some serious problems with the NVidia Drivers after the upgrade. Basically, the new drivers dont seem to install correctly under the new kernel. This conclusion took me a day of laborating with settings, installing packages, uninstalling packages, reinstalling packages and a whole lot of googling. What I have come down to right now is doing the following: sudo apt-get install module-assistantThis will install the module assistant and it will also make sure that you have all the correct linux headers to install the NVidia drivers. Going back to the “Software Sources” under i check the “Unsopported updates”.Then i execute sudo apt-get autoremovesudo apt-get install nvidia-177-kernel-sourcem-a auto-install nvidiaUPDATE! After fiddling around with this Laptop (Lenovo Thinkpad T61) I really just needed these three steps to fix the problem. All of them from X using the regular nv-drivers. In a terminal, run sudo apt-get install module assistant In a terminal, run sudo m-a auto-install nvidia Open the “Hardware Drivers” application and pick the driver you want (177 in my case) and click Activate. If it worked alright, you’ll get the green recycle icon and be asked to reboot to activate the settings.Hopefully, this might help someone. It did work for me and I am now able to work with wobbly windows and all that crap. (Besides some serious 3d stuff ;) ) Anyway. Since I did not save the urls, I cannot give credit to those who have pointed to stuff that did help me on the way, but I’ve actually not find information anywhere yet that solve the problem totally and, well… that’s why I did decide to post in here. Feel free to leave a comment if you got any more info or if you got any help from this.","raw":null,"content":null,"categories":[{"name":"Ubuntu","slug":"ubuntu","permalink":"http://stegenfeldt.github.io/topics/ubuntu/"}],"tags":[{"name":"Drivers","slug":"Drivers","permalink":"http://stegenfeldt.github.io/tag/Drivers/"},{"name":"NVidia","slug":"NVidia","permalink":"http://stegenfeldt.github.io/tag/NVidia/"}]},{"title":"Quest Software acquires eXc and VizionCore","slug":"quest-software-acquires-exc-and-vizioncore","date":"2008-01-30T11:09:18.000Z","updated":"2016-05-19T09:11:09.321Z","comments":true,"path":"tb/quest-software-acquires-exc-and-vizioncore/","link":"","permalink":"http://stegenfeldt.github.io/tb/quest-software-acquires-exc-and-vizioncore/","excerpt":"","keywords":null,"text":"Yes, I am officially slow. But never mind. Quest Software is a rather nice software developer with some interesting products for a wide range of Microsoft systems – like Site Administrator and Recovery Manager for SharePoint – but also database and application servers like SAP and Oracle E-business. I have lately been working with some of their MOSS-related products that, neglecting the somewhat goofy and unspecific manuals, are stable and well worth taking a look at. Quite recently they have acquired two other companies also worth paying attention to as they, too, tend to deliver products that ease things up. eXc does it’s thing in the Microsoft SCOM/MOM arena while VizionCore dances with virtualization techniques. At least, that’s where I’ve come across them both. How will this affect me, then?Not very much it would seem. Here’s what VizionCore says about their part: “The completion of this acquisition signals another major step in Vizioncore’s evolution and growth in the virtualization market,” said David Bieneman, CEO of VizionCore. “While maintaining the autonomy that has made us successful, we will also be able to leverage technologies developed by and acquired by Quest, such as Invirtus and Provision Networks, to enhance and expand the feature sets of VizionCore products. This is very positive news for virtualization customers who will enjoy a richer and robust product set that will help them achieve greater levels of ROI from their investments in virtualization platforms.”In my head, this means that VizionCore will still be VizionCore but with, perhaps, tighter integration with Invirtus. Invirtus was, by the way, a “Strategic Partner” to VizionCore even before the acquisition. eXc then? Well. It is not clearly stated in the press-release as far as I can tell. We can only hope that they will make the decision to rebuild their not-even-web1.0 excuse for a website. And what the hell is up with that logo? Fortunately for us, their design skills – or lack thereof – does not reflect their programming skills. But still… no sane man or woman uses Comic Sans in a logo. Not even jokingly. Actually, using Comic Sans at all should be considered an act of felony. references:Quest Software Continues Its Value Add to Microsoft System CenterQuest Software Completes Acquisition of VizionCore…","raw":null,"content":null,"categories":[{"name":"Technobabble","slug":"tb","permalink":"http://stegenfeldt.github.io/topics/tb/"}],"tags":[{"name":"OpsMgr","slug":"OpsMgr","permalink":"http://stegenfeldt.github.io/tag/OpsMgr/"}]},{"title":"Intel Drivers causes old-school freezes on Windows Vista","slug":"intel-drivers-causes-old-school-freezes-on-windows-vista","date":"2007-12-01T11:31:55.000Z","updated":"2016-05-19T09:11:09.322Z","comments":true,"path":"winvista/intel-drivers-causes-old-school-freezes-on-windows-vista/","link":"","permalink":"http://stegenfeldt.github.io/winvista/intel-drivers-causes-old-school-freezes-on-windows-vista/","excerpt":"","keywords":null,"text":"I recently got a nice new Lenovo ThinkPad T61 laptop at work to replace the old T42 I had earlier. Totally nice with 2,2GHz dual-core, Windows Vista and stuff. Now, there seems to be a problem with some drivers since I get the back-to-the-90s kinda lockups. You know were pretty much everything remotely interactive freeze. No BSOD, no crasches, no reboot. Just a plain freeze and all you can do is to press and hold the powerbutton until the computer powers off. Apparently, these problems are caused by some bug or something in the Intel Turbo Memory Driver and the Intel Matrix Storage Manager in combination with some power-save feature in Windows Vista called “Windows Hybrid Hard Disk Power Savings Mode”. (Christ! Whatever happened to abrevations? I think i want those back. “ITMD and IMSM with WHDDPSM causes hickups”… no… wait.) Aaaanyway.The people over at the forums of Notebookreview.com has experienced this and posted a guide with the appropriate links. Check it out at http://forum.notebookreview.com/showthread.php?t=160154&amp;page=2 Cheers!","raw":null,"content":null,"categories":[{"name":"Windows Vista","slug":"winvista","permalink":"http://stegenfeldt.github.io/topics/winvista/"}],"tags":[{"name":"Drivers","slug":"Drivers","permalink":"http://stegenfeldt.github.io/tag/Drivers/"}]},{"title":"w3Socket in VBScript","slug":"w3socket-in-vbscript","date":"2007-04-21T14:10:05.000Z","updated":"2016-05-19T09:11:09.321Z","comments":true,"path":"vbs/w3socket-in-vbscript/","link":"","permalink":"http://stegenfeldt.github.io/vbs/w3socket-in-vbscript/","excerpt":"","keywords":null,"text":"I’ve been doing quite a lot of VBScripting in a couple of projects lately. The current one requires med to connect to a couple of telnet servers and look for… stuff.Since we’re not in VB6 och .Net i cannot simply user Winsock as normally due to the lack of licensing features in VBS/WSH. Thankfully for me, Dimac has release a nifty little component for free that makes talking telnet in VBS very simple. I thought that, hey! I must share this!So here’s an example in Classic VBS: [vb light=”false”]Dim oTelnetoTelnet = CreateObject(&quot;Socket.Tcp&quot;) With oTelnet.DoTelnetEmulation = True.TelnetEmulation = &quot;TTY&quot;.Host = &quot;192.168.242.1:23&quot;.Open.WaitFor &quot;SLUSSEN login:&quot;.SendLine &quot;ANiftyUsename&quot;.WaitFor &quot;Password:&quot;.SendLine &quot;TEHP@ssw0rd&quot;.WaitFor &quot;~ #&quot;.SendLine &quot;ifconfig&quot;MsgBox .Buffer.CloseEnd With Set oTelnet = Nothing[/vb] Not very hard at all. This one is connecting to my router (with fake user/pwd… DUH!) and there’s no support for setting the prompt type there, thus the “~ #”.The result of running this script with correct login info gives me a popup with the routers NIC-configuration.","raw":null,"content":null,"categories":[{"name":"VBS","slug":"vbs","permalink":"http://stegenfeldt.github.io/topics/vbs/"}],"tags":[{"name":"Script","slug":"Script","permalink":"http://stegenfeldt.github.io/tag/Script/"}]},{"title":"Silly Hibernation doo-doo on WinXP","slug":"silly-hibernation-doo-doo-on-winxp","date":"2006-12-03T11:55:52.000Z","updated":"2016-05-19T09:11:09.320Z","comments":true,"path":"winxp/silly-hibernation-doo-doo-on-winxp/","link":"","permalink":"http://stegenfeldt.github.io/winxp/silly-hibernation-doo-doo-on-winxp/","excerpt":"","keywords":null,"text":"I recently added another 500MB of RAM to my computer… and there was much rejoice. However, after a few days it started to behave erraticly when pressing the Fn+F12 combo (on a ThinkPad that means “Hibernate”). It simply refused to hibernate with the very intuitive error message “Insufficent System Resources Exist to Complete the API”. Anyway. Microsoft has a fix for it, and you don’t have to call them to get it anymore either. Just follow the link below.http://support.microsoft.com/kb/Q909095","raw":null,"content":null,"categories":[{"name":"Windows XP","slug":"winxp","permalink":"http://stegenfeldt.github.io/topics/winxp/"}],"tags":[{"name":"KB","slug":"KB","permalink":"http://stegenfeldt.github.io/tag/KB/"},{"name":"Drivers","slug":"Drivers","permalink":"http://stegenfeldt.github.io/tag/Drivers/"}]}]}